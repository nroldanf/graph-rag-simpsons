{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphRAG Implementation with LlamaIndex\n",
    "\n",
    "[GraphRAG (Graphs + Retrieval Augmented Generation)](https://www.microsoft.com/en-us/research/project/graphrag/) combines the strengths of Retrieval Augmented Generation (RAG) and Query-Focused Summarization (QFS) to effectively handle complex queries over large text datasets. While RAG excels in fetching precise information, it struggles with broader queries that require thematic understanding, a challenge that QFS addresses but cannot scale well. GraphRAG integrates these approaches to offer responsive and thorough querying capabilities across extensive, diverse text corpora.\n",
    "\n",
    "This notebook provides guidance on constructing the GraphRAG pipeline using the LlamaIndex PropertyGraph abstractions using Neo4J."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup LLM and embedding models\n",
    "\n",
    "- LLM used for indexing and querying\n",
    "- Embedding model for embeddings calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# load cofig.yaml\n",
    "with open(\"../config.yaml\", \"r\") as f:\n",
    "\tconfig = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OLLAMA_EMBEDDING_MODEL': 'bge-m3:latest', 'OLLAMA_LLM_MODEL': 'gemma3n:e4b'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "llm = Ollama(\n",
    "    model=config[\"OLLAMA_LLM_MODEL\"], \n",
    "    request_timeout=7200.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "\n",
    "ollama_embedding = OllamaEmbedding(\n",
    "    model_name=config[\"OLLAMA_EMBEDDING_MODEL\"],\n",
    "    base_url=\"http://localhost:11434\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Documents →Text Chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare documents as required by LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/85/py72kfsd3zlgfwv2_dp2wb5m0000gn/T/ipykernel_7148/2780724931.py:6: DtypeWarning: Columns (4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  script_lines_df = pd.read_csv(\"../data/simpsons/simpsons_script_lines.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "characters_df = pd.read_csv(\"../data/simpsons/simpsons_characters.csv\")\n",
    "episodes_df = pd.read_csv(\"../data/simpsons/simpsons_episodes.csv\")\n",
    "locations_df = pd.read_csv(\"../data/simpsons/simpsons_locations.csv\")\n",
    "script_lines_df = pd.read_csv(\"../data/simpsons/simpsons_script_lines.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes_df.sort_values(by=[\"season\", \"id\"], inplace=True)\n",
    "script_lines_df.sort_values(by=[\"episode_id\", \"number\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross script lines data with characters, episodes and locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the episode_id from script_lines_df to get the episode title season and the number_in_season from episodes_df\n",
    "script_lines_df = script_lines_df.merge(\n",
    "\tepisodes_df[[\"id\", \"title\", \"season\", \"number_in_season\", \"number_in_series\"]],\n",
    "\tleft_on=\"episode_id\",\n",
    "\tright_on=\"id\",\n",
    "\tsuffixes=(\"\", \"_episode\"),\n",
    "\thow=\"left\",\n",
    ")\n",
    "# # use the location_id from script_lines_df to get the location name from locations_df\n",
    "script_lines_df = script_lines_df.merge(\n",
    "\tlocations_df[[\"id\", \"normalized_name\"]],\n",
    "\tleft_on=\"location_id\",\n",
    "\tright_on=\"id\",\n",
    "\tsuffixes=(\"\", \"_location\"),\n",
    "\thow=\"left\",\n",
    ")\n",
    "# rename the column to \"location_name\"\n",
    "script_lines_df.rename(columns={\"normalized_name\": \"location_name\"}, inplace=True)\n",
    "# for a given episode_id\n",
    "script_lines_df[\"speaking_line\"] = script_lines_df[\"speaking_line\"].astype(bool)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_episode_text` is a function that given the episode_id will create txt files which content will be documents that we will concatenate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_episode_text(episode_id):\n",
    "\tepisode_lines = script_lines_df[script_lines_df[\"episode_id\"] == episode_id]\n",
    "\t# keep those where normalized_text is not NaN\n",
    "\tepisode_lines = episode_lines[~episode_lines[\"normalized_text\"].isna()]\n",
    "\tspeaking_lines = episode_lines[episode_lines[\"speaking_line\"]]\n",
    "\tlocations = speaking_lines[\"location_name\"].values\n",
    "\tcharacters = speaking_lines[\"raw_character_text\"].str.lower().values\n",
    "\ttext_lines = speaking_lines[\"normalized_text\"].values\n",
    "\t# Concatenate every location name from locations list with the corresponding speaking line from text_lines list and character from characters list\n",
    "\t# such as: \"[location] character_name: speaking line\"\n",
    "\ttext_lines = [f\"[{loc}] ({char}): {text}\" for loc, char, text in zip(locations, characters, text_lines)]\n",
    "\t# Join all the text lines into a single string, separated by newlines\n",
    "\treturn f\"\\n\".join(text_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "output_dir = \"../output/scripts\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# Episodes ids to generate scripts for\n",
    "episode_ids = [128, 129]\n",
    "for episode_id in episode_ids:\n",
    "\tepisode_text = get_episode_text(episode_id)\n",
    "\t# concatenate title, season and number in season\n",
    "\ttitle = script_lines_df[script_lines_df[\"episode_id\"] == episode_id][\"title\"]\n",
    "\tseason = script_lines_df[script_lines_df[\"episode_id\"] == episode_id][\"season\"]\n",
    "\tnumber_in_season = script_lines_df[script_lines_df[\"episode_id\"] == episode_id][\"number_in_season\"]\n",
    "\tnumber_in_series = script_lines_df[script_lines_df[\"episode_id\"] == episode_id][\"number_in_series\"]\n",
    "\tepisode_text = f\"Season: {season.iloc[0]}, Episode: {number_in_season.iloc[0]}, Episode in series: {number_in_series.iloc[0]}\\n\\n{episode_text}\"\n",
    "\tepisode_text = f\"Title: {title.iloc[0]}\\n{episode_text}\"\n",
    "\t# save into a file\n",
    "\twith open(f\"{output_dir}/season_{season.iloc[0]}_episode_{episode_id}_text.txt\", \"w\") as f:\n",
    "\t\tf.write(episode_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare documents as required by LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "season_1_episode_1_text.txt\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "documents = []\n",
    "\n",
    "all_docs_paths = os.listdir(f\"../output/scripts\")\n",
    "# all_docs_paths = [\"season_1_episode_1_text.txt\"]\n",
    "for doc_path in all_docs_paths:\n",
    "\tprint(doc_path)\n",
    "\twith open(f\"../output/scripts/{doc_path}\", \"r\") as f:\n",
    "\t\ttext = f.read()\n",
    "\t\tdocuments.append(Document(text=text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "# Nodes represent chunks of source documents in Llamaindex\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TextNode(id_='d928eed5-bc00-45bf-9fdf-3e786ec47fbe', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e4310346-bd90-49c7-91d5-da64576ba116', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='1a90a181ba8aef84d862b4aac4fc380d1315a6ada7503959a697de5b964f9503'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c8ad0b80-8b5c-44bc-a933-98cf32e2c23e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a2d546ad0d39269729d086fc24927af343904335e55d81c94b07c45bcbdd6f14')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Title: Simpsons Roasting on an Open Fire\\nSeason: 1, Episode: 1, Episode in series: 1\\n\\n[car] (marge simpson): ooo careful homer\\n[car] (homer simpson): theres no time to be careful\\n[car] (homer simpson): were late\\n[auditorium] (marge simpson): sorry excuse us pardon me\\n[auditorium] (homer simpson): hey norman hows it going so you got dragged down here too heh heh how ya doing fred excuse me fred\\n[auditorium] (homer simpson): pardon my galoshes\\n[auditorium] (seymour skinner): wasnt that wonderful and now santas of many lands as presented by the entire second grade class\\n[auditorium] (marge simpson): oh lisas class\\n[auditorium] (janey): frohlich weihnachten -- thats german for merry christmas in germany santas servant ruprecht gives presents to good children and whipping rods to the parents of bad ones\\n[auditorium] (todd flanders): meri kurimasu i am hotseiosha a japanese priest who acts like santa claus i have eyes in the back of my head so children better behave when im nearby\\n[auditorium] (dewey largo): and now presenting lisa simpson as tawanga the santa claus of the south seas\\n[auditorium] (homer simpson): oh its lisa thats ours\\n[auditorium] (seymour skinner): the fourth grade will now favor us with a melody medley of holiday flavorites\\n[auditorium] (children): dashing through the snow in a one-horse open sleigh oer the fields we go laughing all the way ha ha ha bells on bob-tail ring making spirits bright what fun it is to ride and sing this sleighing song tonight\\n[auditorium] (marge simpson): isnt bart sweet homer he sings like a little angel\\n[auditorium] (bart simpson): jingle bells batman smells robin laid an egg the batmobile broke its wheel the joker got away\\n[auditorium] (seymour skinner): the fifth grade will now favor us with a scene from charles dickens a christmas carol\\n[auditorium] (homer simpson): how many grades does this school have\\n[simpson home] (marge simpson): dear friends of the simpson family we had some sadness and some gladness this year first the sadness our little cat snowball was unexpectedly run over and went to kitty heaven but we bought a new little cat snowball iiso i guess life goes on speaking of life going on grampa is still with us feisty as ever maggie is walking by herself lisa got straight as and bart well we love bart the magic of the season has touched us all\\n[simpson home] (homer simpson): marge havent you finished that stupid letter yet\\n[simpson home] (marge simpson): homer sends his love happy holidays\\n[simpson home] (homer simpson): marge\\n[simpson home] (marge simpson): the simpsons\\n[simpson home] (homer simpson): marge wheres the extension cord\\n[simpson home] (marge simpson): oh for heavens sakes homer its in the utility drawer\\n[simpson home] (homer simpson): sorry im just a big kid and i love christmas so much\\n[simpson home] (homer simpson): every year\\n[simpson home] (marge simpson): all right children let me have those letters ill send them to santas workshop at the north pole\\n[simpson home] (bart simpson): oh please theres only one fat guy that brings us presents and his name aint santa\\n[simpson home] (marge simpson): a pony oh lisa youve asked for that for the last three years and i keep telling you santa cant fit a pony into his sleigh cant you take a hint\\n[simpson home] (lisa simpson): but i really want a pony and ive been really really good this year\\n[simpson home] (marge simpson): oh dear maybe bart is a little more realistic\\n[simpson home] (marge simpson): a tattoo\\n[simpson home] (homer simpson): a what\\n[simpson home] (bart simpson): yeah theyre cool and they last the rest of the your life\\n[simpson home] (marge simpson): you will not be getting a tattoo for christmas\\n[simpson home] (homer simpson): yeah if you want one youll have to pay for it out of your', mimetype='text/plain', start_char_idx=0, end_char_idx=3777, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       " TextNode(id_='c8ad0b80-8b5c-44bc-a933-98cf32e2c23e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e4310346-bd90-49c7-91d5-da64576ba116', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='1a90a181ba8aef84d862b4aac4fc380d1315a6ada7503959a697de5b964f9503'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d928eed5-bc00-45bf-9fdf-3e786ec47fbe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bfb5ada576e2c6fc8ea1504f24e775bcca821db7b0ebd192f0d5e4d5db0db15c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='167c7435-d6e1-4cf7-8f16-15a538668cdc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fc9608a83c9205835c9301ddf0b236b6aa68693e286df6c63ecc78479be432a')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='simpson): yeah if you want one youll have to pay for it out of your own allowance\\n[simpson home] (bart simpson): all right\\n[simpson home] (marge simpson): homer\\n[simpson home] (homer simpson): yello\\n[simpson home] (patty bouvier): marge please\\n[simpson home] (homer simpson): whos this\\n[simpson home] (patty bouvier): may i please speak to marge\\n[simpson home] (homer simpson): this is her sister isnt it\\n[simpson home] (patty bouvier): is marge there\\n[simpson home] (homer simpson): who shall i say is calling\\n[simpson home] (patty bouvier): marge please\\n[simpson home] (homer simpson): its your sister\\n[simpson home] (marge simpson): hello\\n[simpson home] (patty bouvier): hello marge its patty selma and i couldnt be more excited about seeing our baby sister for christmas eve\\n[simpson home] (marge simpson): well homer and i are looking forward to your visit too\\n[simpson home] (patty bouvier): somehow i doubt that homers excited of all the men you could have married i dont know why you picked the one whos always so rude to us\\n[simpson home] (bart simpson): good one dad\\n[simpson home] (homer simpson): okay kids prepare to be dazzled marge turn on the juice\\n[simpson home] (homer simpson): what do you think kids\\n[simpson home] (lisa simpson): nice try dad\\n[simpson home] (ned flanders): just hold your horses son hey hey simpson\\n[simpson home] (homer simpson): what is it flanders\\n[simpson home] (ned flanders): do you think this looks okay\\n[simpson home] (mechanical santa): ho ho ho ho ho ho ho ho ho ho ho ho\\n[simpson home] (lisa simpson): ooh\\n[simpson home] (bart simpson): oh neat-o\\n[simpson home] (homer simpson): its too bright that flanders what a big show-off\\n[kitchen] (marge simpson): kids you want to go christmas shopping\\n[kitchen] (lisa simpson): i do\\n[kitchen] (bart simpson): all right the mall\\n[kitchen] (marge simpson): go get your money\\n[kitchen] (homer simpson): spill it marge where have you been hiding the christmas money\\n[kitchen] (marge simpson): oh i have my secrets turn around\\n[kitchen] (marge simpson): you can look now\\n[kitchen] (homer simpson): oh big jar this year\\n[springfield mall] (marge simpson): oh bart thats so sweet its the best present a mother could get and it makes you look so dangerous\\n[the happy sailor tattoo parlor] (bart simpson): one mother please\\n[the happy sailor tattoo parlor] (tattoo man): wait a minute how old are you\\n[the happy sailor tattoo parlor] (bart simpson): twenty-one sir\\n[the happy sailor tattoo parlor] (tattoo man): get in the chair\\n[springfield nuclear power plant] (homer simpson): mm-hmm mmm-hmm mmm-hmm\\n[springfield nuclear power plant] (homer simpson): mmm-hmm mmm-hmm\\n[springfield nuclear power plant] (waylon smithers): attention all personnel please keep working during the following announcement\\n[springfield nuclear power plant] (waylon smithers): and now our boss and friend mr burns\\n[springfield nuclear power plant] (c montgomery burns): hello im proud to announce that we have been able to increase safety\\n[springfield nuclear power plant] (c montgomery burns): here at the plant without increasing the cost to the consumer or affecting management pay raises however for you semi-skilled workers there will be no christmas bonuses\\n[plant] (c montgomery burns): one more thing merry christmas\\n[plant] (homer simpson): oh thank god for the big jar\\n[springfield mall] (marge simpson): wheres that bart\\n[the happy sailor tattoo parlor] (bart simpson): but mom i thought youd like it\\n[dermatology clinic] (doctor zitsofsky): yes mrs simpson we can remove your sons tattoo its a simple routine involving lasers\\n[dermatology clinic] (bart simpson): cool\\n[dermatology clinic] (doctor', mimetype='text/plain', start_char_idx=3710, end_char_idx=7377, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       " TextNode(id_='167c7435-d6e1-4cf7-8f16-15a538668cdc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e4310346-bd90-49c7-91d5-da64576ba116', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='1a90a181ba8aef84d862b4aac4fc380d1315a6ada7503959a697de5b964f9503'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c8ad0b80-8b5c-44bc-a933-98cf32e2c23e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a2d546ad0d39269729d086fc24927af343904335e55d81c94b07c45bcbdd6f14'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e9b6bf8a-acd4-4048-918f-a0985b3ce3c8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cae9517e41abda7448e47a6793f7fbb922a306eef200427314b2e5cd417ce343')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='clinic] (bart simpson): cool\\n[dermatology clinic] (doctor zitsofsky): however it is rather expensive and we must insist on a cash payment up front\\n[dermatology clinic] (marge simpson): cash\\n[dermatology clinic] (doctor zitsofsky): ah-hmmm\\n[dermatology clinic] (marge simpson): thank god for homers christmas bonus\\n[laboratory] (bart simpson): ay carumba\\n[laboratory] (doctor zitsofsky): now whatever you do boy dont squirm you dont want to get this sucker near your eye or groin\\n[simpson home] (bart simpson): ow quit it\\n[simpson home] (bart simpson): ow quit it\\n[simpson home] (bart simpson): ow quit it\\n[simpson home] (bart simpson): ow quit it\\n[simpson home] (homer simpson): hey whats with this\\n[simpson home] (bart simpson): ow quit it it used to be a real boss tattoo\\n[simpson home] (lisa simpson): but mom had to spend all the christmas money having it surgically removed\\n[simpson home] (homer simpson): its true the jars empty oh my god were ruined christmas is cancelled no presents for anyone\\n[simpson home] (marge simpson): dont worry homer well just have to stretch your christmas bonus even further this year\\n[simpson home] (marge simpson): homer\\n[simpson home] (homer simpson): oh yeah my christmas bonus how silly of me thisll be the best christmas yet the best any family ever had heh-heh\\n[simpson home] (mechanical santa): ho ho ho ho ho ho ho ho ho ho ho ho\\n[simpson home] (marge simpson): i get the feeling theres something you havent told me homer\\n[simpson home] (homer simpson): oh i love you marge\\n[simpson home] (marge simpson): homer you tell me that all the time\\n[simpson home] (homer simpson): oh good because i do love you and i dont deserve you as much as a guy with a fat wallet and a credit card that wont set off that horrible beeping\\n[simpson home] (marge simpson): but i think it does have something to do with your christmas bonus i keep asking for it but\\n[simpson home] (homer simpson): marge well let me be honest with you\\n[simpson home] (marge simpson): yes\\n[simpson home] (homer simpson): well i want to do the christmas shopping this year\\n[simpson home] (marge simpson): well sure okay\\n[circus of values] (homer simpson): marge marge marge lets see oooh look pantyhose practical and alluring a six-pack oh only four ninety nine\\n[circus of values] (homer simpson): oooh pads of paper i bet bart can think of a million things to do with these that just leaves little maggie oh look a little squeak-toy it says its for dogs but she cant read\\n[circus of values] (ned flanders): ow oh simpson its you\\n[circus of values] (homer simpson): hello flanders\\n[circus of values] (ned flanders): oh my what a little mess weve got here well which ones are yours and which ones are mine\\n[circus of values] (homer simpson): well lets see\\n[circus of values] (ned flanders): this ones mine and this ones mine this ones mine and this--\\n[circus of values] (homer simpson): theyre all yours\\n[circus of values] (todd flanders): hey mr simpson you dropped your pork chop\\n[circus of values] (homer simpson): gimme that\\n[circus of values] (ned flanders): well happy holidays simpson\\n[circus of values] (todd flanders): gee dad this is gonna be the best christmas ever\\n[circus of values] (ned flanders): you bet\\n[moe tavern] (moe szyslak): whats the matter homer somebody leave a lumpa coal in your stocking youve been sitting there sucking on a beer all day long\\n[moe tavern] (homer simpson): so\\n[moe tavern] (moe szyslak): so its christmas\\n[moe tavern] (homer simpson): thanks moe\\n[moe tavern] (barney gumble): drinks all around\\n[moe tavern] (homer simpson): whats with the crazy getup barn\\n[moe tavern] (barney', mimetype='text/plain', start_char_idx=7320, end_char_idx=10945, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       " TextNode(id_='e9b6bf8a-acd4-4048-918f-a0985b3ce3c8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e4310346-bd90-49c7-91d5-da64576ba116', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='1a90a181ba8aef84d862b4aac4fc380d1315a6ada7503959a697de5b964f9503'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='167c7435-d6e1-4cf7-8f16-15a538668cdc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fc9608a83c9205835c9301ddf0b236b6aa68693e286df6c63ecc78479be432a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5cc3ebbf-4488-4f83-8b53-4df7971b25e7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f64e44ec1213e48f9a8e1c02c8c4385accdaa7e379d47ccc00ea45ea1e29dd1d')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='simpson): whats with the crazy getup barn\\n[moe tavern] (barney gumble): i got me a part-time job working as a santa down at the mall\\n[moe tavern] (homer simpson): wow can i do that\\n[moe tavern] (barney gumble): i dont know theyre pretty selective\\n[springfield mall] (interviewer): do you like children\\n[springfield mall] (homer simpson): what do you mean all the time even when theyre nuts\\n[springfield mall] (homer simpson): oh i certainly do\\n[springfield mall] (interviewer): welcome aboard simpson pending your successful completion of our training program that is\\n[santa school] (students): ho ho ho ho ho ho ho ho ho ho ho ho\\n[santa school] (teacher): what is it now simpson\\n[santa school] (homer simpson): huh when do we get paid\\n[santa school] (teacher): not a dime till christmas eve now from the top\\n[santa school] (students): ho ho ho ho ho ho\\n[santa school] (homer simpson): dasher dancer\\n[santa school] (teacher): um-hmm\\n[santa school] (homer simpson): prancer\\n[santa school] (teacher): um-hmm\\n[santa school] (homer simpson): nixon comet cupid donna dixon\\n[santa school] (teacher): sit down simpson\\n[santa school] (homer simpson): and what would you like little boy\\n[santa school] (teacher): youre not really santa tubby\\n[santa school] (homer simpson): why you little eggheaded\\n[santa school] (teacher): no no homer if such an emergency arises just tell them santas very busy this time of year and youre one of his helpers\\n[santa school] (homer simpson): oh i knew that one too\\n[simpson home] (marge simpson): homer why are you seven hours late\\n[simpson home] (homer simpson): not a word marge im heading straight for the tub\\n[simpson home] (marge simpson): but homer my sisters are here dont you want to say hello\\n[simpson home] (bart simpson): oh dad youre finally home\\n[simpson home] (lisa simpson): daddy were so glad to see you\\n[simpson home] (homer simpson): what why oh yeah hello patty hello selma how was your trip\\n[simpson home] (selma bouvier): fine\\n[simpson home] (homer simpson): you both look well\\n[simpson home] (patty bouvier): thank you\\n[simpson home] (homer simpson): yeah well merry christmas\\n[simpson home] (selma bouvier): oh its christmas you wouldnt know it around here\\n[simpson home] (homer simpson): and why is that\\n[simpson home] (patty bouvier): well for one thing theres no tree\\n[simpson home] (homer simpson): well i was just on my way out to get one\\n[simpson home] (lisa simpson): can we go too dad\\n[simpson home] (bart simpson): can we\\n[simpson home] (homer simpson): no\\n[street] (voice): hey you what do you think youre doing\\n[street] (homer simpson): uh-oh\\n[street] (voice): hey hey come back here\\n[simpson home] (homer simpson): so what do you think kids beauty isnt it\\n[simpson home] (bart simpson): yeah homer\\n[simpson home] (lisa simpson): way to go dad\\n[simpson home] (selma bouvier): why is there a birdhouse in it\\n[simpson home] (homer simpson): thats an ornament\\n[simpson home] (patty bouvier): do i smell gunpowder\\n[springfield mall] (little boy): and then i want some robotoids and then i want a goop monster and then i want a great big giant\\n[springfield mall] (homer simpson): ah son you dont need all that junk im sure youve already got something much more important a decent home and a loving father who would do anything for you hey i couldnt afford lunch gimme a bite of that donut\\n[springfield mall] (milhouse van houten): get a load of that quote unquote santa\\n[springfield mall] (lewis clark): i cant believe those kids are fallin for it\\n[springfield mall] (bart simpson): hey milhouse i dare you to sit on his lap\\n[springfield', mimetype='text/plain', start_char_idx=10883, end_char_idx=14474, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       " TextNode(id_='5cc3ebbf-4488-4f83-8b53-4df7971b25e7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e4310346-bd90-49c7-91d5-da64576ba116', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='1a90a181ba8aef84d862b4aac4fc380d1315a6ada7503959a697de5b964f9503'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e9b6bf8a-acd4-4048-918f-a0985b3ce3c8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cae9517e41abda7448e47a6793f7fbb922a306eef200427314b2e5cd417ce343'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='83e3db21-b989-4309-bc0c-d96148c6f849', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ff8daa67d1916d97c0a89d598c74a39959be17cba2d795a9c91a54f33c9946dc')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='(bart simpson): hey milhouse i dare you to sit on his lap\\n[springfield mall] (milhouse van houten): oh yeah well i dare you to yank his beard off\\n[springfield mall] (bart simpson): ah touché\\n[springfield mall] (little girl): i hope you feel better santa\\n[springfield mall] (homer simpson): i will when mrs clauss sisters get out of town thanks for listening kid\\n[springfield mall] (bart simpson): hey santa whats shaking\\n[springfield mall] (homer simpson): whats your name bart ner -- er -- little partner\\n[springfield mall] (bart simpson): im bart simpson who the hell are you\\n[springfield mall] (homer simpson): im jolly old saint nick\\n[springfield mall] (bart simpson): oh yeah well just see about that\\n[springfield mall] (bart simpson): homer\\n[springfield mall] (homer simpson): i want a word with you in santas workshop little boy cover for me elfie\\n[santa workshop] (bart simpson): dont kill me dad i didnt know it was you\\n[santa workshop] (homer simpson): nobody knows its a secret i didnt get my bonus this year but to keep the family from missing out on christmas id do anything\\n[santa workshop] (bart simpson): ill say dad you must really love us to sink so low\\n[santa workshop] (homer simpson): now lets not get mushy son i still have a job to do\\n[workshop] (homer simpson): hey little ones santas back ho ho\\n[workshop] (homer simpson): arrgh -- damn it to\\n[personnel office] (homer simpson): ah son one day youre gonna know the satisfaction of payday receiving a big fat check for a job well done\\n[personnel office] (clerk): simpson homer here you go\\n[personnel office] (homer simpson): come on son lets go cash this baby and get presents for -- thirteen bucks hey wait a minute\\n[personnel office] (clerk): thats right one hundred and twenty dollars gross less social security --\\n[personnel office] (homer simpson): yeah\\n[personnel office] (clerk): less unemployment insurance --\\n[personnel office] (homer simpson): but\\n[personnel office] (clerk): less santa training --\\n[personnel office] (homer simpson): santa\\n[personnel office] (clerk): less costume purchase --\\n[personnel office] (homer simpson): wait a minute\\n[personnel office] (clerk): less beard rental less christmas club\\n[personnel office] (homer simpson): but but\\n[personnel office] (clerk): see you next year\\n[personnel office] (bart simpson): come on dad lets go home\\n[personnel office] (homer simpson): thirteen bucks we cant get anything for thirteen bucks\\n[personnel office] (barney gumble): all right thirteen big ones springfield downs here i come\\n[personnel office] (homer simpson): what\\n[personnel office] (barney gumble): you heard me im going to the dog track i got a hot little puppy in the fourth race wanna come\\n[personnel office] (homer simpson): sorry barney i may be a total washout as a father but im not gonna take my kid to some sleazy dog track on christmas eve\\n[personnel office] (barney gumble): come on simpson the dogs name is whirlwind ten to one shot money in the bank\\n[personnel office] (homer simpson): uh-uh\\n[personnel office] (bart simpson): ah come on dad this can be the miracle that saves the simpsons christmas if tv has taught me anything its that miracles always happen to poor kids at christmas it happened to tiny tim it happened to charlie brown it happened to the smurfs and its gonna happen to us\\n[personnel office] (homer simpson): well okay lets go\\n[personnel office] (homer simpson): whos tiny tim\\n[simpson home] (bubbles): hey moldy do you think santa will be able to find elf county under all this snow\\n[simpson home] (moldy): i doubt it bubbles well be sad little elves this christmas\\n[simpson home] (lisa simpson): oh no\\n[simpson home] (grampa simpson): oh brother\\n[simpson home] (selma bouvier): wheres your husband\\n[simpson home] (patty bouvier): yeah\\n[simpson home] (selma bouvier): its getting', mimetype='text/plain', start_char_idx=14404, end_char_idx=18224, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       " TextNode(id_='83e3db21-b989-4309-bc0c-d96148c6f849', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e4310346-bd90-49c7-91d5-da64576ba116', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='1a90a181ba8aef84d862b4aac4fc380d1315a6ada7503959a697de5b964f9503'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5cc3ebbf-4488-4f83-8b53-4df7971b25e7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f64e44ec1213e48f9a8e1c02c8c4385accdaa7e379d47ccc00ea45ea1e29dd1d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a400f3ae-8013-47dc-8636-0fbd4a83cf4d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99fe18754026ab6e3a6a31132a886176fde44283ba0b74355d4dcaa14430fd4a')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='bouvier): yeah\\n[simpson home] (selma bouvier): its getting late\\n[simpson home] (marge simpson): he said he went caroling with bart\\n[springfield downs dog track] (barney gumble): were in the money were in the money we got a lot of what it takes to get along\\n[springfield downs dog track] (homer simpson): i cant believe im doing this\\n[springfield downs] (little boy): can we open our presents now dad\\n[springfield downs] (father): you know the tradition son not till the eighth race\\n[paddock] (homer simpson): hey barney which one is whirlwind\\n[paddock] (barney gumble): number six thats our lucky dog right over there hes won his last five races\\n[paddock] (homer simpson): what that scrawny little bag of bones\\n[paddock] (bart simpson): come on dad theyre all scrawny little bags of bones\\n[paddock] (homer simpson): yeah youre right i guess whirlwind is our only hope for a merry christmas\\n[paddock] (announcer): attention racing fans we have a late scratch in the fourth race number eight sir galahad will be replaced by santas little helper once again sir galahad has been replaced by santas little helper\\n[paddock] (homer simpson): bart did you hear that what a name -- santas little helper its a sign its an omen\\n[paddock] (bart simpson): its a coincidence dad\\n[springfield down] (homer simpson): what are the odds on santas little helper\\n[springfield down] (ticket seller): ninety nine to one\\n[springfield down] (homer simpson): whoa ninety-nine times thirteen equals mer-ry christmas\\n[springfield down] (bart simpson): i got a bad feeling about this\\n[springfield down] (homer simpson): dont you believe in me son\\n[springfield down] (bart simpson): uh\\n[springfield down] (homer simpson): come on boy sometimes your faith is all that keeps me going\\n[springfield down] (bart simpson): oh go for it dad\\n[springfield down] (homer simpson): thats my boy everything on santas little helper\\n[simpson home] (elf 1): three cheers for brainy\\n[simpson home] (elves): hip hip hooray hip hip hooray hip hip hooray\\n[simpson home] (lisa simpson): yay\\n[simpson home] (grampa simpson): unadulterated pap\\n[simpson home] (patty bouvier): its almost nine oclock\\n[simpson home] (selma bouvier): where is homer anyway\\n[simpson home] (patty bouvier): its so typical of the big doofus to spoil it all\\n[simpson home] (lisa simpson): what aunt patty\\n[simpson home] (patty bouvier): oh nothing dear im just trashing your father\\n[simpson home] (lisa simpson): well i wish you wouldnt because aside from the fact that he has the same frailties as all human beings hes the only father i have therefore he is my model of manhood and my estimation of him will govern the prospects of my adult relationships so i hope you bear in mind that any knock at him is a knock at me and i am far to young to defend myself against such onslaughts\\n[simpson home] (patty bouvier): um-hm go watch your cartoon show dear\\n[springfield downs] (homer simpson): come on bart kiss the ticket for good luck not that we need it heh-heh-heh\\n[springfield downs] (announcer): here comes screwy the mechanical rabbit and theyre off\\n[springfield downs] (announcer): around the first turn\\n[springfield downs] (bart simpson): come on santas little helper\\n[springfield downs] (bart simpson): come on dog go man go come on santas little helper run baby run\\n[springfield downs] (homer simpson): come on santas little helper go go go run your tail off\\n[springfield downs] (announcer): its whirlwind in the lead\\n[springfield downs] (announcer): and coming up on the left is quadruped followed by dog o war and fido\\n[springfield downs] (homer simpson): go go\\n[springfield downs] (bart simpson): go santas little helper\\n[springfield downs] (homer simpson): come on boy\\n[springfield downs] (bart simpson): come on get that rabbit\\n[springfield downs] (announcer): dog', mimetype='text/plain', start_char_idx=18166, end_char_idx=21968, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       " TextNode(id_='a400f3ae-8013-47dc-8636-0fbd4a83cf4d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e4310346-bd90-49c7-91d5-da64576ba116', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='1a90a181ba8aef84d862b4aac4fc380d1315a6ada7503959a697de5b964f9503'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='83e3db21-b989-4309-bc0c-d96148c6f849', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ff8daa67d1916d97c0a89d598c74a39959be17cba2d795a9c91a54f33c9946dc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='88cb4a8a-0793-4cc7-9fcd-3f5dea4c3e56', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c161cc1754a2441d3c47f63dcc99557179355566ee31c0ecd9da2b94050d6cef')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='simpson): come on get that rabbit\\n[springfield downs] (announcer): dog of war coming up fast on the outside and with a lock on last place its santas little helper\\n[springfield downs] (bart simpson): dont worry dad maybe this is just for suspense before the miracle happens\\n[springfield downs] (announcer): around the clubhouse turn whirlwind is staking out a big lead a couple of lengths quadruped fighting it out and coming up fast chew my shoe\\n[springfield downs] (announcer): and its whirlwind by a country mile and in second chew my shoe followed by dog o war\\n[springfield downs] (bart simpson): it doesnt seem possible but i guess tv has betrayed me\\n[springfield downs] (homer simpson): i dont want to leave till our dog finishes\\n[springfield downs] (homer simpson): ah forget it lets go\\n[springfield downs parking lot] (homer simpson): find any winners son\\n[springfield downs parking lot] (bart simpson): sorry dad\\n[springfield downs parking lot] (barney gumble): hey-hey simpson whatd i tell you whirlwind lets go daria\\n[springfield downs parking lot] (voice): beat it scram get lost you came in last for the last time\\n[springfield downs parking lot] (bart simpson): look dad its santas little helper\\n[springfield downs parking lot] (dogs owner): and dont come back\\n[springfield downs parking lot] (homer simpson): oh no you dont no no get away from me uh-uh\\n[springfield downs parking lot] (bart simpson): oh can we keep him dad please\\n[springfield downs parking lot] (homer simpson): but hes a loser hes pathetic hes\\n[springfield downs parking lot] (homer simpson): -- a simpson\\n[simpson home] (marge simpson): maybe i should call the police\\n[simpson home] (patty bouvier): oh hell sober up\\n[simpson home] (selma bouvier): yeah and come staggering home\\n[simpson home] (patty bouvier): um-hm smelling of cheap perfume\\n[simpson home] (marge simpson): homer\\n[simpson home] (homer simpson): all right look everybody i have a confession to make\\n[simpson home] (selma bouvier): this should be good\\n[simpson home] (homer simpson): i didnt get my christmas bonus i tried not to let it ruin christmas for everybody but no matter what i did i just couldnt --\\n[simpson home] (bart simpson): hey everybody look what we got\\n[simpson home] (lisa simpson): a dog all right dad\\n[simpson home] (marge simpson): good bless him\\n[simpson home] (lisa simpson): so love at first sight is possible\\n[simpson home] (bart simpson): and if he runs away hell be easy to catch\\n[simpson home] (marge simpson): this is the best gift of all homer\\n[simpson home] (homer simpson): it is\\n[simpson home] (marge simpson): yes something to share our love --\\n[simpson home] (marge simpson): -- and frighten prowlers\\n[simpson home] (lisa simpson): whats his name\\n[simpson home] (homer simpson): number eight i mean santas little helper\\n[simpson home] (lisa simpson): rudolph the red nosed reindeer had a very shiny nose and if you ever saw it you would even say it glowed\\n[simpson home] (bart simpson): like a light bulb\\n[simpson home] (homer simpson): bart\\n[simpson home] (lisa simpson): all of the other reindeer used to laugh and call him names\\n[simpson home] (lisa simpson): like shine-ola\\n[simpson home] (homer simpson): lisa\\n[simpson home] (lisa simpson): they never let poor rudolph join in any reindeer games\\n[simpson home] (bart simpson): like strip poker\\n[simpson home] (homer simpson): im warning you two\\n[simpson home] (lisa simpson): then one foggy christmas eve santa came to say\\n[simpson home] (marge simpson): take it homer\\n[simpson home] (homer simpson): rudolph with your nose over here so you can guide my sleigh today\\n[simpson home] (marge simpson): oh homer\\n[simpson home] (lisa simpson): then all the reindeer', mimetype='text/plain', start_char_idx=21898, end_char_idx=25598, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       " TextNode(id_='88cb4a8a-0793-4cc7-9fcd-3f5dea4c3e56', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e4310346-bd90-49c7-91d5-da64576ba116', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='1a90a181ba8aef84d862b4aac4fc380d1315a6ada7503959a697de5b964f9503'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a400f3ae-8013-47dc-8636-0fbd4a83cf4d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99fe18754026ab6e3a6a31132a886176fde44283ba0b74355d4dcaa14430fd4a')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='oh homer\\n[simpson home] (lisa simpson): then all the reindeer loved him as they shouted out with glee rudolph the red nosed reindeer youll go down in history\\n[simpson home] (bart simpson): like attila the hun', mimetype='text/plain', start_char_idx=25537, end_char_idx=25745, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Chunks → Knowledge Graph\n",
    "\n",
    "The GraphRAGExtractor class is designed to extract triples (subject-relation-object) from text and enrich them by adding descriptions for entities and relationships to their properties using an LLM.\n",
    "\n",
    "This functionality is similar to that of the `SimpleLLMPathExtractor`, but includes additional enhancements to handle entity, relationship descriptions. For guidance on implementation, you may look at similar existing [extractors](https://docs.llamaindex.ai/en/latest/examples/property_graph/Dynamic_KG_Extraction/?h=comparing).\n",
    "\n",
    "Other paths (i.e. triplets) extractors implemented in llamaindex include:\n",
    "- `SimpleLLMPathExtractor`\n",
    "- `SchemaLLMPathExtractor`\n",
    "- `DynamicLLMPathExtractor` -> This one allows to start with initial nodes, relationships and their corresponding properties.\n",
    "\n",
    "Here's a breakdown of its functionality:\n",
    "\n",
    "**Key Components:**\n",
    "\n",
    "1. `llm:` The language model used for extraction.\n",
    "2. `extract_prompt:` A prompt template used to guide the LLM in extracting information.\n",
    "3. `parse_fn:` A function to parse the LLM's output into structured data.\n",
    "4. `max_paths_per_chunk:` Limits the number of triples extracted per text chunk.\n",
    "5. `num_workers:` For parallel processing of multiple text nodes.\n",
    "\n",
    "\n",
    "**Main Methods:**\n",
    "\n",
    "1. `__call__:` The entry point for processing a list of text nodes.\n",
    "2. `acall:` An asynchronous version of __call__ for improved performance.\n",
    "3. `_aextract:` The core method that processes each individual node.\n",
    "\n",
    "\n",
    "**Extraction Process:**\n",
    "\n",
    "For each input node (chunk of text):\n",
    "1. It sends the text to the LLM along with the extraction prompt.\n",
    "2. The LLM's response is parsed to extract entities, relationships, descriptions for entities and relations.\n",
    "3. Entities are converted into `EntityNode` objects. Entity description is stored in metadata\n",
    "4. Relationships are converted into `Relation` objects. Relationship description is stored in metadata.\n",
    "5. These are added to the node's metadata under `KG_NODES_KEY` and `KG_RELATIONS_KEY`.\n",
    "\n",
    "**NOTE:** In the current implementation, we are using only relationship descriptions. In the next implementation, we will utilize entity descriptions during the retrieval stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook utilities to path event loop behavior (event loop is already running in ipython)\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import asyncio\n",
    "\n",
    "from typing import Any, List, Callable, Optional, Union\n",
    "\n",
    "from llama_index.core.async_utils import run_jobs\n",
    "from llama_index.core.indices.property_graph.utils import (\n",
    "    default_parse_triplets_fn,\n",
    ")\n",
    "from llama_index.core.graph_stores.types import (\n",
    "    EntityNode,\n",
    "    Relation,\n",
    "    KG_NODES_KEY,\n",
    "    KG_RELATIONS_KEY,\n",
    ")\n",
    "from llama_index.core.llms.llm import LLM\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.prompts.default_prompts import (\n",
    "    DEFAULT_KG_TRIPLET_EXTRACT_PROMPT,\n",
    ")\n",
    "from llama_index.core.schema import TransformComponent, BaseNode\n",
    "from prompts import KG_TRIPLET_EXTRACT_TMPL\n",
    "\n",
    "\n",
    "class GraphRAGExtractor(TransformComponent):\n",
    "    \"\"\"Extract triples from a graph.\n",
    "\n",
    "    Uses an LLM and a simple prompt + output parsing to extract paths (i.e. triples) and entity, relation descriptions from text.\n",
    "\n",
    "    Args:\n",
    "        llm (LLM):\n",
    "            The language model to use.\n",
    "        extract_prompt (Union[str, PromptTemplate]):\n",
    "            The prompt to use for extracting triples.\n",
    "        parse_fn (callable):\n",
    "            A function to parse the output of the language model.\n",
    "        num_workers (int):\n",
    "            The number of workers to use for parallel processing.\n",
    "        max_paths_per_chunk (int):\n",
    "            The maximum number of paths to extract per chunk.\n",
    "    \"\"\"\n",
    "\n",
    "    llm: LLM\n",
    "    extract_prompt: PromptTemplate\n",
    "    parse_fn: Callable\n",
    "    num_workers: int\n",
    "    max_paths_per_chunk: int\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm: Optional[LLM] = None,\n",
    "        extract_prompt: Optional[Union[str, PromptTemplate]] = None,\n",
    "        parse_fn: Callable = default_parse_triplets_fn,\n",
    "        max_paths_per_chunk: int = 10,\n",
    "        num_workers: int = 4,\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        from llama_index.core import Settings\n",
    "\n",
    "        if isinstance(extract_prompt, str):\n",
    "            extract_prompt = PromptTemplate(extract_prompt)\n",
    "\n",
    "        super().__init__(\n",
    "            llm=llm or Settings.llm,\n",
    "            extract_prompt=extract_prompt or DEFAULT_KG_TRIPLET_EXTRACT_PROMPT,\n",
    "            parse_fn=parse_fn,\n",
    "            num_workers=num_workers,\n",
    "            max_paths_per_chunk=max_paths_per_chunk,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def class_name(cls) -> str:\n",
    "        return \"GraphExtractor\"\n",
    "\n",
    "    def __call__(\n",
    "        self, nodes: List[BaseNode], show_progress: bool = False, **kwargs: Any\n",
    "    ) -> List[BaseNode]:\n",
    "        \"\"\"Extract triples from nodes.\"\"\"\n",
    "        return asyncio.run(\n",
    "            self.acall(nodes, show_progress=show_progress, **kwargs)\n",
    "        )\n",
    "\n",
    "    async def _aextract(self, node: BaseNode) -> BaseNode:\n",
    "        \"\"\"Extract triples from a node (chunk).\"\"\"\n",
    "        assert hasattr(node, \"text\")\n",
    "\n",
    "        text = node.get_content(metadata_mode=\"llm\")\n",
    "        # Extract entities and relationships from the text using the LLM\n",
    "        # and parse them into a list of JSON objects\n",
    "        # entities and relationships\n",
    "        try:\n",
    "            llm_response = await self.llm.apredict(\n",
    "                self.extract_prompt,\n",
    "                text=text,\n",
    "                max_knowledge_triplets=self.max_paths_per_chunk,\n",
    "            )\n",
    "            entities, entities_relationship = self.parse_fn(llm_response)\n",
    "        except ValueError:\n",
    "            entities = []\n",
    "            entities_relationship = []\n",
    "\n",
    "\t\t# Initialize\n",
    "        existing_nodes = node.metadata.pop(KG_NODES_KEY, [])\n",
    "        existing_relations = node.metadata.pop(KG_RELATIONS_KEY, [])\t\n",
    "        \t\n",
    "\t\t# Create EntityNode and Relation objects from parsed information\n",
    "        entity_metadata = node.metadata.copy()\n",
    "        for entity_name, entity_type, entity_description in entities:\n",
    "            entity_metadata[\"entity_description\"] = entity_description\n",
    "            entity_node = EntityNode(\n",
    "                name=entity_name, label=entity_type, properties=entity_metadata\n",
    "            )\n",
    "            existing_nodes.append(entity_node)\n",
    "\n",
    "\t\t# Create Relation objects from parsed information\n",
    "        relation_metadata = node.metadata.copy()\n",
    "        for triple in entities_relationship:\n",
    "            subj, obj, rel, description = triple\n",
    "            relation_metadata[\"relationship_description\"] = description\n",
    "            rel_node = Relation(\n",
    "                label=rel,\n",
    "                source_id=subj,\n",
    "                target_id=obj,\n",
    "                properties=relation_metadata,\n",
    "            )\n",
    "\n",
    "            existing_relations.append(rel_node)\n",
    "\t\t# Index them under the corresponding key\n",
    "        node.metadata[KG_NODES_KEY] = existing_nodes\n",
    "        node.metadata[KG_RELATIONS_KEY] = existing_relations\n",
    "        return node\n",
    "\n",
    "    async def acall(\n",
    "        self, nodes: List[BaseNode], show_progress: bool = False, **kwargs: Any\n",
    "    ) -> List[BaseNode]:\n",
    "        \"\"\"Extract triples from nodes async.\"\"\"\n",
    "        jobs = []\n",
    "        for node in nodes:\n",
    "            jobs.append(self._aextract(node))\n",
    "\n",
    "        return await run_jobs(\n",
    "            jobs,\n",
    "            workers=self.num_workers,\n",
    "            show_progress=show_progress,\n",
    "            desc=\"Extracting paths from text\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that parses the LLM response into structured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def parse_fn(response_str: str) -> Any:\n",
    "    json_pattern = r\"\\{.*\\}\"\n",
    "    match = re.search(json_pattern, response_str, re.DOTALL)\n",
    "    entities = []\n",
    "    relationships = []\n",
    "    if not match:\n",
    "        return entities, relationships\n",
    "    json_str = match.group(0)\n",
    "    try:\n",
    "        data = json.loads(json_str)\n",
    "        entities = [\n",
    "            (\n",
    "                entity[\"entity_name\"],\n",
    "                entity[\"entity_type\"],\n",
    "                entity[\"entity_description\"],\n",
    "            )\n",
    "            for entity in data.get(\"entities\", [])\n",
    "        ]\n",
    "        relationships = [\n",
    "            (\n",
    "                relation[\"source_entity\"],\n",
    "                relation[\"target_entity\"],\n",
    "                relation[\"relation\"],\n",
    "                relation[\"relationship_description\"],\n",
    "            )\n",
    "            for relation in data.get(\"relationships\", [])\n",
    "        ]\n",
    "        return entities, relationships\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Error parsing JSON:\", e)\n",
    "        return entities, relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Graph → Graph Communities and Community Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `GraphRAGStore` class is an extension of the `Neo4jPropertyGraphStore`class, designed to implement GraphRAG pipeline. Here's a breakdown of its key components and functions:\n",
    "\n",
    "The class uses community detection algorithms to group related nodes in the graph and then it generates summaries for each community using an LLM.\n",
    "\n",
    "\n",
    "**Key Methods:**\n",
    "\n",
    "`build_communities():`\n",
    "\n",
    "1. Converts the internal graph representation to a NetworkX graph.\n",
    "\n",
    "2. Applies the hierarchical Leiden algorithm for community detection.\n",
    "\n",
    "3. Collects detailed information about each community.\n",
    "\n",
    "4. Generates summaries for each community.\n",
    "\n",
    "`generate_community_summary(text):`\n",
    "\n",
    "1. Uses LLM to generate a summary of the relationships in a community.\n",
    "2. The summary includes entity names and a synthesis of relationship descriptions.\n",
    "\n",
    "`_create_nx_graph():`\n",
    "\n",
    "1. Converts the internal graph representation to a NetworkX graph for community detection.\n",
    "\n",
    "`_collect_community_info(nx_graph, clusters):`\n",
    "\n",
    "1. Collects detailed information about each node based on its community.\n",
    "2. Creates a string representation of each relationship within a community.\n",
    "\n",
    "`_summarize_communities(community_info):`\n",
    "\n",
    "1. Generates and stores summaries for each community using LLM.\n",
    "\n",
    "`get_community_summaries():`\n",
    "\n",
    "1. Returns the community summaries by building them if not already done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasroldan/Documents/Loka/Pycon2025/graph-rag-simpsons/.venv/lib/python3.11/site-packages/graspologic/layouts/colors.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import networkx as nx\n",
    "from graspologic.partition import hierarchical_leiden\n",
    "from collections import defaultdict\n",
    "\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore\n",
    "from prompts import COMMUNITY_SUMMARY_TMPL\n",
    "\n",
    "\n",
    "\n",
    "class GraphRAGStore(Neo4jPropertyGraphStore):\n",
    "    community_summary = {}\n",
    "    entity_info = None\n",
    "    max_cluster_size = 5\n",
    "    llm: LLM\n",
    "\n",
    "    def build_communities(self):\n",
    "        \"\"\"Builds communities from the graph and summarizes them.\"\"\"\n",
    "        nx_graph = self._create_nx_graph()\n",
    "        # Use Leiden algorithm to create communities\n",
    "        community_hierarchical_clusters = hierarchical_leiden(\n",
    "            nx_graph, max_cluster_size=self.max_cluster_size\n",
    "        )\n",
    "        self.entity_info, community_info = self._collect_community_info(\n",
    "            nx_graph, community_hierarchical_clusters\n",
    "        )\n",
    "        self._summarize_communities(community_info)\n",
    "\n",
    "    def _create_nx_graph(self):\n",
    "        \"\"\"Converts internal graph representation to NetworkX graph.\"\"\"\n",
    "        nx_graph = nx.Graph()\n",
    "        triplets = self.get_triplets()\n",
    "        for entity1, relation, entity2 in triplets:\n",
    "            nx_graph.add_node(entity1.name)\n",
    "            nx_graph.add_node(entity2.name)\n",
    "            nx_graph.add_edge(\n",
    "                relation.source_id,\n",
    "                relation.target_id,\n",
    "                relationship=relation.label,\n",
    "                description=relation.properties[\"relationship_description\"],\n",
    "            )\n",
    "        return nx_graph\n",
    "\n",
    "    def _collect_community_info(self, nx_graph, clusters):\n",
    "        \"\"\"\n",
    "        Collect information for each node based on their community,\n",
    "        allowing entities to belong to multiple clusters.\n",
    "        \"\"\"\n",
    "        entity_info = defaultdict(set)\n",
    "        community_info = defaultdict(list)\n",
    "\n",
    "        for item in clusters:\n",
    "            node = item.node\n",
    "            cluster_id = item.cluster\n",
    "\n",
    "            # Update entity_info\n",
    "            entity_info[node].add(cluster_id)\n",
    "\n",
    "            for neighbor in nx_graph.neighbors(node):\n",
    "                edge_data = nx_graph.get_edge_data(node, neighbor)\n",
    "                if edge_data:\n",
    "                    detail = f\"{node} -> {neighbor} -> {edge_data['relationship']} -> {edge_data['description']}\"\n",
    "                    community_info[cluster_id].append(detail)\n",
    "\n",
    "        # Convert sets to lists for easier serialization if needed\n",
    "        entity_info = {k: list(v) for k, v in entity_info.items()}\n",
    "\n",
    "        return dict(entity_info), dict(community_info)\n",
    "\n",
    "    def generate_community_summary(self, text):\n",
    "        \"\"\"Generate summary for a given text using an LLM.\"\"\"\n",
    "        messages = [\n",
    "            ChatMessage(\n",
    "                role=\"system\",\n",
    "                content=COMMUNITY_SUMMARY_TMPL,\n",
    "            ),\n",
    "            ChatMessage(role=\"user\", content=text),\n",
    "        ]\n",
    "        # hardcode\n",
    "        # llm = Ollama(model=\"gemma3n:e4b\", request_timeout=60.0)\n",
    "        response = llm.chat(messages)\n",
    "        clean_response = re.sub(r\"^assistant:\\s*\", \"\", str(response)).strip()\n",
    "        return clean_response\n",
    "\n",
    "    def _summarize_communities(self, community_info):\n",
    "        \"\"\"Generate and store summaries for each community.\"\"\"\n",
    "        for community_id, details in community_info.items():\n",
    "            details_text = (\n",
    "                \"\\n\".join(details) + \".\"\n",
    "            )  # Ensure it ends with a period\n",
    "            self.community_summary[\n",
    "                community_id\n",
    "            ] = self.generate_community_summary(details_text)\n",
    "\n",
    "    def get_community_summaries(self):\n",
    "        \"\"\"Returns the community summaries, building them if not already done.\"\"\"\n",
    "        if not self.community_summary:\n",
    "            self.build_communities()\n",
    "        return self.community_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community Summaries → Community Answers → Global Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GraphRAGQueryEngine class is a custom query engine designed to process queries using the GraphRAG approach. It leverages the community summaries generated by the GraphRAGStore to answer user queries. Here's a breakdown of its functionality:\n",
    "\n",
    "**Main Components:**\n",
    "\n",
    "`graph_store:` An instance of GraphRAGStore, which contains the community summaries.\n",
    "`llm:` A Language Model (LLM) used for generating and aggregating answers.\n",
    "\n",
    "\n",
    "**Key Methods:**\n",
    "\n",
    "`custom_query(query_str: str)`\n",
    "\n",
    "1. This is the main entry point for processing a query. It retrieves community summaries, generates answers from each summary, and then aggregates these answers into a final response.\n",
    "\n",
    "`generate_answer_from_summary(community_summary, query):`\n",
    "\n",
    "1. Generates an answer for the query based on a single community summary.\n",
    "Uses the LLM to interpret the community summary in the context of the query.\n",
    "\n",
    "`aggregate_answers(community_answers):`\n",
    "\n",
    "1. Combines individual answers from different communities into a coherent final response.\n",
    "2. Uses the LLM to synthesize multiple perspectives into a single, concise answer.\n",
    "\n",
    "\n",
    "**Query Processing Flow:**\n",
    "\n",
    "1. Retrieve community summaries from the graph store.\n",
    "2. For each community summary, generate a specific answer to the query.\n",
    "3. Aggregate all community-specific answers into a final, coherent response.\n",
    "\n",
    "\n",
    "**Example usage:**\n",
    "\n",
    "```\n",
    "query_engine = GraphRAGQueryEngine(graph_store=graph_store, llm=llm)\n",
    "\n",
    "response = query_engine.query(\"query\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import CustomQueryEngine\n",
    "from llama_index.core import PropertyGraphIndex\n",
    "import re\n",
    "\n",
    "\n",
    "class GraphRAGQueryEngine(CustomQueryEngine):\n",
    "    graph_store: GraphRAGStore\n",
    "    index: PropertyGraphIndex\n",
    "    llm: LLM\n",
    "    similarity_top_k: int = 20\n",
    "\n",
    "    def custom_query(self, query_str: str) -> str:\n",
    "        \"\"\"Process all community summaries to generate answers to a specific query.\"\"\"\n",
    "\n",
    "        entities = self.get_entities(query_str, self.similarity_top_k)\n",
    "\n",
    "        community_ids = self.retrieve_entity_communities(\n",
    "            self.graph_store.entity_info, entities\n",
    "        )\n",
    "        community_summaries = self.graph_store.get_community_summaries()\n",
    "        community_answers = [\n",
    "            self.generate_answer_from_summary(community_summary, query_str)\n",
    "            for id, community_summary in community_summaries.items()\n",
    "            if id in community_ids\n",
    "        ]\n",
    "\n",
    "        final_answer = self.aggregate_answers(community_answers)\n",
    "        return final_answer\n",
    "\n",
    "    def get_entities(self, query_str, similarity_top_k):\n",
    "        nodes_retrieved = self.index.as_retriever(\n",
    "            similarity_top_k=similarity_top_k\n",
    "        ).retrieve(query_str)\n",
    "\n",
    "        enitites = set()\n",
    "        pattern = (\n",
    "            r\"^(\\w+(?:\\s+\\w+)*)\\s*->\\s*([a-zA-Z\\s]+?)\\s*->\\s*(\\w+(?:\\s+\\w+)*)$\"\n",
    "        )\n",
    "\n",
    "        for node in nodes_retrieved:\n",
    "            matches = re.findall(\n",
    "                pattern, node.text, re.MULTILINE | re.IGNORECASE\n",
    "            )\n",
    "\n",
    "            for match in matches:\n",
    "                subject = match[0]\n",
    "                obj = match[2]\n",
    "                enitites.add(subject)\n",
    "                enitites.add(obj)\n",
    "\n",
    "        return list(enitites)\n",
    "\n",
    "    def retrieve_entity_communities(self, entity_info, entities):\n",
    "        \"\"\"\n",
    "        Retrieve cluster information for given entities, allowing for multiple clusters per entity.\n",
    "\n",
    "        Args:\n",
    "        entity_info (dict): Dictionary mapping entities to their cluster IDs (list).\n",
    "        entities (list): List of entity names to retrieve information for.\n",
    "\n",
    "        Returns:\n",
    "        List of community or cluster IDs to which an entity belongs.\n",
    "        \"\"\"\n",
    "        community_ids = []\n",
    "\n",
    "        for entity in entities:\n",
    "            if entity in entity_info:\n",
    "                community_ids.extend(entity_info[entity])\n",
    "\n",
    "        return list(set(community_ids))\n",
    "\n",
    "    def generate_answer_from_summary(self, community_summary, query):\n",
    "        \"\"\"Generate an answer from a community summary based on a given query using LLM.\"\"\"\n",
    "        prompt = (\n",
    "            f\"Given the community summary: {community_summary}, \"\n",
    "            f\"how would you answer the following query? Query: {query}\"\n",
    "        )\n",
    "        messages = [\n",
    "            ChatMessage(role=\"system\", content=prompt),\n",
    "            ChatMessage(\n",
    "                role=\"user\",\n",
    "                content=\"I need an answer based on the above information.\",\n",
    "            ),\n",
    "        ]\n",
    "        response = self.llm.chat(messages)\n",
    "        cleaned_response = re.sub(r\"^assistant:\\s*\", \"\", str(response)).strip()\n",
    "        return cleaned_response\n",
    "\n",
    "    def aggregate_answers(self, community_answers):\n",
    "        \"\"\"Aggregate individual community answers into a final, coherent response.\"\"\"\n",
    "        prompt = \"Combine the following intermediate answers into a final, concise response.\"\n",
    "        messages = [\n",
    "            ChatMessage(role=\"system\", content=prompt),\n",
    "            ChatMessage(\n",
    "                role=\"user\",\n",
    "                content=f\"Intermediate answers: {community_answers}\",\n",
    "            ),\n",
    "        ]\n",
    "        final_response = self.llm.chat(messages)\n",
    "        cleaned_final_response = re.sub(\n",
    "            r\"^assistant:\\s*\", \"\", str(final_response)\n",
    "        ).strip()\n",
    "        return cleaned_final_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Build End to End GraphRAG Pipeline\n",
    "\n",
    "Now that we have defined all the necessary components, let’s construct the GraphRAG pipeline:\n",
    "\n",
    "1. Create nodes/chunks from the text.\n",
    "2. Build a PropertyGraphIndex using `GraphRAGExtractor` and `GraphRAGStore`.\n",
    "3. Construct communities and generate a summary for each community using the graph built above.\n",
    "4. Create a `GraphRAGQueryEngine` and begin querying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build ProperGraphIndex using `GraphRAGExtractor` and `GraphRAGStore`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_extractor = GraphRAGExtractor(\n",
    "    # LLM model to use for extracting triplets\n",
    "    llm=llm,\n",
    "    # Prompt passed to the LLM to extract triplets\n",
    "    extract_prompt=KG_TRIPLET_EXTRACT_TMPL,\n",
    "    # Maximum number of triplets to extract per chunk\n",
    "    max_paths_per_chunk=2,\n",
    "    # Function to parse the output of the LLM\n",
    "    parse_fn=parse_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: used to be `Neo4jPGStore`\n",
    "graph_store = GraphRAGStore(\n",
    "    username=\"neo4j\", \n",
    "    password=\"neo4j123\",\n",
    "    # Copy from Neo4j desktop\n",
    "    url=\"neo4j://127.0.0.1:7687\",\n",
    "    # database name\n",
    "    database=\"simpsons\",\n",
    ")\n",
    "# LLM model to use for generating community summaries\n",
    "graph_store.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting paths from text: 100%|██████████| 8/8 [05:54<00:00, 44.29s/it]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.59s/it]\n",
      "Generating embeddings: 100%|██████████| 12/12 [00:04<00:00,  2.79it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "index = PropertyGraphIndex(\n",
    "    # Documents to index\n",
    "    nodes=nodes,\n",
    "    # Embedding model to use for indexing\n",
    "    embed_model=ollama_embedding,\n",
    "    # LLM model to use for querying\n",
    "    llm=llm,\n",
    "    # Knowledge graph extractor\n",
    "    kg_extractors=[kg_extractor],\n",
    "    # Graph store and community and community summary building logic\n",
    "    property_graph_store=graph_store,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[EntityNode(label='Person', embedding=None, properties={'id': 'Homer Simpson', 'entity_description': \"Bart's father, a well-meaning but often incompetent and gluttonous man. He works at the Springfield Nuclear Power Plant and is a frequent source of comedic situations.\", 'triplet_source_id': '12408fcb-c66a-4f21-9442-7014650c045a'}, name='Homer Simpson'),\n",
       " Relation(label='receives payment from', source_id='Homer Simpson', target_id='Clerk', properties={'triplet_source_id': '12408fcb-c66a-4f21-9442-7014650c045a', 'relationship_description': 'Homer Simpson receives his paycheck from the Clerk at the Personnel Office.'}),\n",
       " EntityNode(label='Person', embedding=None, properties={'id': 'Clerk', 'entity_description': 'An employee at the personnel office responsible for distributing paychecks and handling administrative tasks.', 'triplet_source_id': '12408fcb-c66a-4f21-9442-7014650c045a'}, name='Clerk')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.property_graph_store.get_triplets()[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'Homer Simpson',\n",
       " 'entity_description': \"Bart's father, a well-meaning but often incompetent and gluttonous man. He works at the Springfield Nuclear Power Plant and is a frequent source of comedic situations.\",\n",
       " 'triplet_source_id': '12408fcb-c66a-4f21-9442-7014650c045a'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.property_graph_store.get_triplets()[10][0].properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'triplet_source_id': '12408fcb-c66a-4f21-9442-7014650c045a',\n",
       " 'relationship_description': 'Homer Simpson receives his paycheck from the Clerk at the Personnel Office.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.property_graph_store.get_triplets()[10][1].properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build communities\n",
    "\n",
    "This will create communities and summary for each community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.property_graph_store.build_communities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create QueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = GraphRAGQueryEngine(\n",
    "    graph_store=index.property_graph_store,\n",
    "    # llm to answer the query given community summaries\n",
    "    llm=llm,\n",
    "    index=index,\n",
    "    similarity_top_k=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the provided summaries, **Homer Simpson** has the greatest number of co-occurrences with Bart Simpson. This is supported by multiple points: they share a residence at the Simpson home, Homer expresses a desire to adopt Bart, and they have direct interactions, including Bart calling Homer. Furthermore, they share a belief in Santa Claus, with Homer even portraying him, creating a significant connection. While Bart also has a close relationship with Lisa Simpson (being her brother), the summaries highlight the more frequent and direct interactions between Homer and Bart."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"What's the character that has the greatest amount of co-ocurrences with Bart Simpson?\"\n",
    ")\n",
    "display(Markdown(f\"{response.response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Homer Simpson episodes frequently explore themes of **Family & Relationships**, particularly the dynamics between Homer, Marge, and their children, Bart and Lisa. **Work & Employment** is a consistent element, often highlighting the mundane or absurd aspects of Homer's jobs at the Springfield Nuclear Power Plant and Santa's Workshop. **Christmas & the Holiday Season** is a major recurring theme, encompassing traditions, celebrations, and Homer's aspirations to embody the spirit of Santa Claus.  **Hope & Belief**, especially regarding fantastical concepts like \"Whiirlwind\" and Santa, and **Bart's Mischief & Playfulness** are also prominent, often intertwined with his relationships and desires for self-expression.  Furthermore, the **cultural impact of Santa Claus** and the **community of Elf County** are recurring elements, often explored through Homer's role-playing and Bart's childhood wonder."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"What are the top 5 themes discussed in the episodes?\"\n",
    ")\n",
    "display(Markdown(f\"{response.response}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying (once indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_store = GraphRAGStore(\n",
    "    username=\"neo4j\", \n",
    "    password=\"neo4j123\",\n",
    "    # Copy from Neo4j desktop\n",
    "    url=\"neo4j://127.0.0.1:7687\",\n",
    "    # database name\n",
    "    database=\"simpsons\",\n",
    ")\n",
    "# LLM model to use for generating community summaries\n",
    "graph_store.llm = llm\n",
    "# load from existing graph/vector store\n",
    "index = PropertyGraphIndex.from_existing(\n",
    "    property_graph_store=graph_store,\n",
    "    embed_model=ollama_embedding,\n",
    "    llm=llm,\n",
    "    # embed_kg_nodes=True,\n",
    ")\n",
    "# index = PropertyGraphIndex(\n",
    "#     # Documents to index\n",
    "#     nodes=nodes,\n",
    "#     # Embedding model to use for indexing\n",
    "#     embed_model=ollama_embedding,\n",
    "#     # LLM model to use for querying\n",
    "#     llm=llm,\n",
    "#     # Knowledge graph extractor\n",
    "#     kg_extractors=[kg_extractor],\n",
    "#     # Graph store and community and community summary building logic\n",
    "#     property_graph_store=graph_store,\n",
    "#     show_progress=True,\n",
    "# )\n",
    "query_engine = GraphRAGQueryEngine(\n",
    "    graph_store=graph_store,\n",
    "    llm=llm,\n",
    "    index=index,\n",
    "    similarity_top_k=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m nest_asyncio.apply()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m response = \u001b[43mquery_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ms the character that has the greatest amount of co-ocurrences with Bart Simpson?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m display(Markdown(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.response\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Loka/Pycon2025/graph-rag-simpsons/.venv/lib/python3.11/site-packages/llama_index_instrumentation/dispatcher.py:319\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    316\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    322\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Loka/Pycon2025/graph-rag-simpsons/.venv/lib/python3.11/site-packages/llama_index/core/query_engine/custom.py:44\u001b[39m, in \u001b[36mCustomQueryEngine.query\u001b[39m\u001b[34m(self, str_or_query_bundle)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     43\u001b[39m     query_str = str_or_query_bundle\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m raw_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcustom_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m     46\u001b[39m     Response(raw_response)\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(raw_response, \u001b[38;5;28mstr\u001b[39m)\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m raw_response\n\u001b[32m     49\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Loka/Pycon2025/graph-rag-simpsons/.venv/lib/python3.11/site-packages/llama_index_instrumentation/dispatcher.py:319\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    316\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    322\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mGraphRAGQueryEngine.custom_query\u001b[39m\u001b[34m(self, query_str)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Process all community summaries to generate answers to a specific query.\"\"\"\u001b[39;00m\n\u001b[32m     15\u001b[39m entities = \u001b[38;5;28mself\u001b[39m.get_entities(query_str, \u001b[38;5;28mself\u001b[39m.similarity_top_k)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m community_ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretrieve_entity_communities\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgraph_store\u001b[49m\u001b[43m.\u001b[49m\u001b[43mentity_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentities\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m community_summaries = \u001b[38;5;28mself\u001b[39m.graph_store.get_community_summaries()\n\u001b[32m     21\u001b[39m community_answers = [\n\u001b[32m     22\u001b[39m     \u001b[38;5;28mself\u001b[39m.generate_answer_from_summary(community_summary, query_str)\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m, community_summary \u001b[38;5;129;01min\u001b[39;00m community_summaries.items()\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m community_ids\n\u001b[32m     25\u001b[39m ]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mGraphRAGQueryEngine.retrieve_entity_communities\u001b[39m\u001b[34m(self, entity_info, entities)\u001b[39m\n\u001b[32m     64\u001b[39m community_ids = []\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m entity \u001b[38;5;129;01min\u001b[39;00m entities:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mentity\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mentity_info\u001b[49m:\n\u001b[32m     68\u001b[39m         community_ids.extend(entity_info[entity])\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(community_ids))\n",
      "\u001b[31mTypeError\u001b[39m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"What's the character that has the greatest amount of co-ocurrences with Bart Simpson?\"\n",
    ")\n",
    "display(Markdown(f\"{response.response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the provided summaries, recurring themes in *The Simpsons* episodes involving specific characters include:\n",
       "\n",
       "**Homer Simpson:** Family dynamics, workplace mishaps and employment, addiction and coping mechanisms (Duff Beer), material desires and financial struggles, and conflict with authority (particularly Montgomery Burns).\n",
       "\n",
       "**Marge Simpson:** Family bonds, education and mentorship (both receiving and imparting), activities and leisure, Springfield life, and bowling.\n",
       "\n",
       "**Lisa Simpson:** Family relationships, education and mentorship, personal interests and passions, social interactions and gift-giving, and adventure and exploration.\n",
       "\n",
       "**Bart Simpson:** School and education (and its consequences), rebellion and mischief, family dynamics, pop culture and fandom, and location-specific adventures within Springfield.\n",
       "\n",
       "**Dewey Largo:** Music education and the relationship with Lisa Simpson.\n",
       "\n",
       "It's important to note that these themes are inferred from the provided summaries and a more comprehensive analysis of individual episodes would likely reveal additional recurring elements."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"What are the top 5 themes discussed in the episodes?\"\n",
    ")\n",
    "display(Markdown(f\"{response.response}\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llamaindex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
