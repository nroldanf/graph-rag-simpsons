{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "433c5c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from typing import List, Dict, Any\n",
    "import json\n",
    "import re\n",
    "import zipfile\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from faiss import write_index, read_index\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "import yaml\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf74f9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cofig.yaml\n",
    "with open(\"../config.yaml\", \"r\") as f:\n",
    "\tconfig = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7611ed5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = OllamaEmbedding(\n",
    "    model_name=config[\"OLLAMA_EMBEDDING_MODEL\"],\n",
    "    base_url=\"http://localhost:11434\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f07020a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6722 characters\n",
      "Loaded 600 episodes\n",
      "Loaded 4459 locations\n",
      "Loaded 158271 script lines\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Load all Simpsons CSV files into dataframes from data/simpsons/\"\"\"\n",
    "files_path = \"../data/simpsons/\"\n",
    "\n",
    "characters_df = pd.read_csv(os.path.join(files_path, 'simpsons_characters.csv'))\n",
    "episodes_df = pd.read_csv(os.path.join(files_path, 'simpsons_episodes.csv'))\n",
    "locations_df = pd.read_csv(os.path.join(files_path, 'simpsons_locations.csv'))\n",
    "script_lines_df = pd.read_csv(\n",
    "    os.path.join(files_path, 'simpsons_script_lines.csv'),\n",
    "    quotechar='\"',\n",
    "    dtype={\n",
    "        \"speaking_line\": \"string\", \n",
    "        \"character_id\": \"string\", \n",
    "    },\n",
    "    na_values=[\"\", \"NaN\"],\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# speaking_line to boolean\n",
    "script_lines_df[\"speaking_line\"] = script_lines_df[\"speaking_line\"].map({\"TRUE\": True, \"FALSE\": False})\n",
    "\n",
    "# character_id to int64 with support for NaN\n",
    "script_lines_df[\"character_id\"] = pd.to_numeric(script_lines_df[\"character_id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(characters_df)} characters\")\n",
    "print(f\"Loaded {len(episodes_df)} episodes\")\n",
    "print(f\"Loaded {len(locations_df)} locations\")\n",
    "print(f\"Loaded {len(script_lines_df)} script lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "975e47a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes_df.sort_values(by=[\"season\", \"id\"], inplace=True)\n",
    "script_lines_df.sort_values(by=[\"episode_id\", \"number\"], inplace=True)\n",
    "\n",
    "# Use the episode_id from script_lines_df to get the episode title season and the number_in_season from episodes_df\n",
    "merged_lines_df = script_lines_df.merge(\n",
    "  episodes_df[[\"id\", \"title\", \"season\", \"number_in_season\", \"number_in_series\"]],\n",
    "  left_on=\"episode_id\",\n",
    "  right_on=\"id\",\n",
    "  how=\"left\",\n",
    "  suffixes=(\"\", \"_episode\"),\n",
    ")\n",
    "# use the location_id from script_lines_df to get the location name from locations_df\n",
    "merged_lines_df = merged_lines_df.merge(\n",
    "  locations_df[[\"id\", \"normalized_name\"]],\n",
    "  left_on=\"location_id\",\n",
    "  right_on=\"id\",\n",
    "  how=\"left\",\n",
    "  suffixes=(\"\", \"_location\"),\n",
    ")\n",
    "# rename the column to \"location_name\"\n",
    "merged_lines_df.rename(columns={\"normalized_name\": \"location_name\"}, inplace=True)\n",
    "# use the character_id from script_lines_df to get the character name from characters_df\n",
    "\n",
    "# concatenate all the raw_text when speaking_line == True or true into a single string\n",
    "# for a given episode_id\n",
    "merged_lines_df[\"speaking_line\"] = merged_lines_df[\"speaking_line\"].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ae2e0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>number</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>timestamp_in_ms</th>\n",
       "      <th>speaking_line</th>\n",
       "      <th>character_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>raw_location_text</th>\n",
       "      <th>spoken_words</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>id_episode</th>\n",
       "      <th>title</th>\n",
       "      <th>season</th>\n",
       "      <th>number_in_season</th>\n",
       "      <th>number_in_series</th>\n",
       "      <th>id_location</th>\n",
       "      <th>location_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(Street: ext. street - establishing - night)</td>\n",
       "      <td>8000</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Simpsons Roasting on an Open Fire</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(Car: int. car - night)</td>\n",
       "      <td>8000</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Car</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Simpsons Roasting on an Open Fire</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Marge Simpson: Ooo, careful, Homer.</td>\n",
       "      <td>8000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Marge Simpson</td>\n",
       "      <td>Car</td>\n",
       "      <td>Ooo, careful, Homer.</td>\n",
       "      <td>ooo careful homer</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Simpsons Roasting on an Open Fire</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  episode_id  number                                      raw_text  \\\n",
       "0   1           1       0  (Street: ext. street - establishing - night)   \n",
       "1   2           1       1                       (Car: int. car - night)   \n",
       "2   3           1       2           Marge Simpson: Ooo, careful, Homer.   \n",
       "\n",
       "  timestamp_in_ms  speaking_line  character_id  location_id  \\\n",
       "0            8000           True          <NA>          1.0   \n",
       "1            8000           True          <NA>          2.0   \n",
       "2            8000           True             1          2.0   \n",
       "\n",
       "  raw_character_text raw_location_text          spoken_words  \\\n",
       "0                NaN            Street                   NaN   \n",
       "1                NaN               Car                   NaN   \n",
       "2      Marge Simpson               Car  Ooo, careful, Homer.   \n",
       "\n",
       "     normalized_text word_count  id_episode  \\\n",
       "0                NaN        NaN           1   \n",
       "1                NaN        NaN           1   \n",
       "2  ooo careful homer          3           1   \n",
       "\n",
       "                               title  season  number_in_season  \\\n",
       "0  Simpsons Roasting on an Open Fire       1                 1   \n",
       "1  Simpsons Roasting on an Open Fire       1                 1   \n",
       "2  Simpsons Roasting on an Open Fire       1                 1   \n",
       "\n",
       "   number_in_series  id_location location_name  \n",
       "0                 1          1.0        street  \n",
       "1                 1          2.0           car  \n",
       "2                 1          2.0           car  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_lines_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12062dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_episode_text(episode_id):\n",
    "\tepisode_lines = merged_lines_df[merged_lines_df[\"episode_id\"] == episode_id]\n",
    "\tepisode_lines = episode_lines[~episode_lines[\"normalized_text\"].isna()]\n",
    "\t# drop those where normalized_name is NaN\n",
    "\tepisode_lines = episode_lines.dropna()\n",
    "\tspeaking_lines = episode_lines[episode_lines[\"speaking_line\"]]\n",
    "\tlocations = speaking_lines[\"location_name\"].tolist()\n",
    "\tcharacters = speaking_lines[\"raw_character_text\"].str.lower().values\n",
    "\ttext_lines = speaking_lines[\"normalized_text\"].tolist()\n",
    "\t# Concatenate every location name from locations list with the corresponding speaking line from text_lines list and character from characters list\n",
    "\t# such as: \"[location] character_name: speaking line\"\n",
    "\ttext_lines = [f\"[{loc}] ({char}): {text}\" for loc, char, text in zip(locations, characters, text_lines)]\n",
    "\t# Join all the text lines into a single string, separated by newlines\n",
    "\treturn f\"\\n\".join(text_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eddd73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 episodes not written, check 'skipped_episodes.json' file for more info\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"../limited_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# Episodes ids to generate scripts for\n",
    "\n",
    "written_episodes = []\n",
    "skipped_episodes = []\n",
    "\n",
    "episode_ids = [128, 129]\n",
    "for episode_id in episode_ids:\n",
    "    if episode_id not in merged_lines_df[\"episode_id\"].values:\n",
    "        skipped_episodes.append({\n",
    "            \"episode_id\": episode_id,\n",
    "            \"reason\": \"no script lines\"\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    episode_text = get_episode_text(episode_id)\n",
    "\n",
    "    title_row = merged_lines_df[merged_lines_df[\"episode_id\"] == episode_id]\n",
    "\n",
    "    # skip if no usable lines (e.g. only NaNs)\n",
    "    if title_row.empty or not episode_text.strip():\n",
    "        print(f\"Skipping episode {episode_id} (no valid lines)\")\n",
    "        skipped_episodes.append({\n",
    "            \"episode_id\": episode_id,\n",
    "            \"reason\": \"no valid lines\"\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    title = title_row[\"title\"].iloc[0]\n",
    "    season = title_row[\"season\"].iloc[0]\n",
    "    number_in_season = title_row[\"number_in_season\"].iloc[0]\n",
    "    number_in_series = title_row[\"number_in_series\"].iloc[0]\n",
    "\n",
    "    episode_text = f\"Season: {season}, Episode: {number_in_season}, Episode in series: {number_in_series}\\n\\n{episode_text}\"\n",
    "    episode_text = f\"Title: {title}\\n{episode_text}\"\n",
    "    written_episodes.append(episode_id)\n",
    "\n",
    "# save into a file\t\n",
    "    with open(f\"{output_dir}/scripts/season_{season}_episode_{episode_id}_text.txt\", \"w\") as f:\n",
    "            f.write(episode_text)\n",
    "\n",
    "with open(f\"{output_dir}/skipped_episodes.json\", \"w\") as f:\n",
    "    json.dump(skipped_episodes, f, indent=2)\n",
    "    \n",
    "print(len(skipped_episodes),\"episodes not written, check 'skipped_episodes.json' file for more info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "666eb35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "all_docs_paths = os.listdir(f\"../limited_output/scripts\")\n",
    "# all_docs_paths = [\"season_1_episode_1_text.txt\"]\n",
    "for doc_path in all_docs_paths:\n",
    "\twith open(f\"../limited_output/scripts/{doc_path}\", \"r\") as f:\n",
    "\t\ttext = f.read()\n",
    "\t\tdocuments.append(Document(text=text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7b5be4",
   "metadata": {},
   "source": [
    "# Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71405ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = SentenceSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "# Nodes represent chunks of source documents in Llamaindex\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7d4c58",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f551c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74874ca649b84ef08426540fed967ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texts = [node.text for node in nodes]\n",
    "\n",
    "embeddings: List[List] = embedding_model.get_text_embedding_batch(texts, show_progress=True)\n",
    "embeddings: np.ndarray = np.array(embeddings, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f009885",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\n",
    "    f\"../limited_output/embeddings/embeddings_bge_m3.npz\",\n",
    "    texts=np.array(texts),\n",
    "    embeddings=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f77e3c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(f\"../limited_output/embeddings/embeddings_bge_m3.npz\", allow_pickle=True)\n",
    "texts = data[\"texts\"]\n",
    "embeddings = data[\"embeddings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5f03b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Build FAISS index for similarity search\"\"\"\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)  # Inner product for cosine similarity\n",
    "\n",
    "# Normalize embeddings for cosine similarity\n",
    "faiss.normalize_L2(embeddings)\n",
    "index.add(embeddings.astype('float32'))\n",
    "\n",
    "output_faiss_path = f\"../limited_output/faiss_index_bge_m3.index\"\n",
    "faiss.write_index(index, output_faiss_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e856e44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Ollama LLM\n",
    "# https://docs.llamaindex.ai/en/stable/api_reference/llms/ollama/\n",
    "llm = Ollama(\n",
    "    model=config[\"OLLAMA_LLM_MODEL\"],\n",
    "    temperature=0.7,\n",
    "    request_timeout = 7200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c1fa3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = \"What are the top 5 themes discussed in the episodes?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "849d868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = embedding_model.get_text_embedding_batch([query_1])\n",
    "query_embedding: np.ndarray = np.array(query_embedding, dtype=np.float32)\n",
    "faiss.normalize_L2(query_embedding)\n",
    "\n",
    "scores, indices = index.search(query_embedding.astype('float32'), k=10)\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, idx in enumerate(indices[0]):\n",
    "    results.append({\n",
    "        'content': texts[idx],\n",
    "        'score': float(scores[0][i])\n",
    "    })\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af8e7450",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_2 = \"Which characters interacted directly with Mr. Burns on the day of the shooting?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57e666dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = query_2\n",
    "\"\"\"Generate response using OpenAI with retrieved context\"\"\"\n",
    "# Prepare context from retrieved documents\n",
    "\n",
    "context = \"\"\n",
    "for doc in results:\n",
    "    context += f\"{doc['content']}\\n\\n\"\n",
    "\n",
    "# Create prompt\n",
    "prompt = f\"\"\"\n",
    "You are a knowledgeable assistant about The Simpsons TV show. Use the following context to answer the user's question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Please provide a comprehensive answer based ONLY on the context provided. If the context doesn't contain enough information to fully answer the question, mention what information is available and what might be missing.\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", \n",
    "        content=\"You are a helpful assistant specializing in The Simpsons TV show.\",\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        role=\"user\",\n",
    "        content=prompt\n",
    "    )\n",
    "]\n",
    "response = llm.chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8be8c9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(message=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={'tool_calls': None, 'thinking': None}, blocks=[TextBlock(block_type='text', text=' The top 5 themes discussed in \"Who Shot Mr. Burns? (Part Two)\" episode of The Simpsons are as follows:\\n\\n1. Mystery and Suspense: The main theme revolves around the mysterious shooting of Montgomery Burns and the subsequent investigation to find out who the culprit is. The episode involves various characters being suspected, evidence collection, and interviews.\\n\\n2. Revenge and Anger: Many characters in Springfield have reasons to be angry at Mr. Burns for one reason or another, and this theme is explored as several suspects express their desire for revenge against him. This includes Waylon Smithers, Moe Szyslak, Groundskeeper Willie, Tito Puente, and even the Simpson family.\\n\\n3. Power and Control: Mr. Burns is one of the wealthiest and most powerful characters in Springfield, and his actions often affect the lives of others around him. The episode showcases how people struggle to get back at him for his mistreatment or take advantage of his weaknesses.\\n\\n4. Corruption and Greed: Mr. Burns\\' oil drilling operation causes problems for the elementary school, and the school administration is forced to eliminate non-essential programs like music due to financial constraints. This highlights the corruption and greed that often accompany wealth and power in Springfield.\\n\\n5. Family Dynamics: The Simpson family plays a significant role in the episode, with Lisa investigating the case and trying to help find the culprit, while Homer is accused of attempted murder. Their relationship dynamics, particularly their conflicts and disagreements, are also explored throughout the episode.')]), raw={'model': 'mistral', 'created_at': '2025-07-06T10:28:11.058885Z', 'done': True, 'done_reason': 'stop', 'total_duration': 138199695917, 'load_duration': 3197305708, 'prompt_eval_count': 8735, 'prompt_eval_duration': 72133558291, 'eval_count': 351, 'eval_duration': 62847106167, 'message': Message(role='assistant', content=' The top 5 themes discussed in \"Who Shot Mr. Burns? (Part Two)\" episode of The Simpsons are as follows:\\n\\n1. Mystery and Suspense: The main theme revolves around the mysterious shooting of Montgomery Burns and the subsequent investigation to find out who the culprit is. The episode involves various characters being suspected, evidence collection, and interviews.\\n\\n2. Revenge and Anger: Many characters in Springfield have reasons to be angry at Mr. Burns for one reason or another, and this theme is explored as several suspects express their desire for revenge against him. This includes Waylon Smithers, Moe Szyslak, Groundskeeper Willie, Tito Puente, and even the Simpson family.\\n\\n3. Power and Control: Mr. Burns is one of the wealthiest and most powerful characters in Springfield, and his actions often affect the lives of others around him. The episode showcases how people struggle to get back at him for his mistreatment or take advantage of his weaknesses.\\n\\n4. Corruption and Greed: Mr. Burns\\' oil drilling operation causes problems for the elementary school, and the school administration is forced to eliminate non-essential programs like music due to financial constraints. This highlights the corruption and greed that often accompany wealth and power in Springfield.\\n\\n5. Family Dynamics: The Simpson family plays a significant role in the episode, with Lisa investigating the case and trying to help find the culprit, while Homer is accused of attempted murder. Their relationship dynamics, particularly their conflicts and disagreements, are also explored throughout the episode.', thinking=None, images=None, tool_calls=None), 'usage': {'prompt_tokens': 8735, 'completion_tokens': 351, 'total_tokens': 9086}}, delta=None, logprobs=None, additional_kwargs={})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2377787f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
