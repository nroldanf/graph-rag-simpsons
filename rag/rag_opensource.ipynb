{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "433c5c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import faiss\n",
    "from typing import List, Dict, Any\n",
    "import json\n",
    "import re\n",
    "import zipfile\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf74f9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# load cofig.yaml\n",
    "with open(\"../config.yaml\", \"r\") as f:\n",
    "\tconfig = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7611ed5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "\n",
    "embedding_model = OllamaEmbedding(\n",
    "    model_name=config[\"OLLAMA_EMBEDDING_MODEL\"],\n",
    "    base_url=\"http://localhost:11434\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f07020a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_simpsons_data():\n",
    "    \"\"\"Load all Simpsons CSV files into dataframes\"\"\"\n",
    "    # Load the CSV files\n",
    "    characters_df = pd.read_csv('../data/simpsons/simpsons_characters.csv')\n",
    "    episodes_df = pd.read_csv('../data/simpsons/simpsons_episodes.csv')\n",
    "    locations_df = pd.read_csv('../data/simpsons/simpsons_locations.csv')\n",
    "    script_lines_df = pd.read_csv('../data/simpsons/simpsons_script_lines.csv')\n",
    "    \n",
    "    print(f\"Loaded {len(characters_df)} characters, {len(episodes_df)} episodes, {len(locations_df)} locations, {len(script_lines_df)} script lines\")\n",
    "    \n",
    "    return characters_df, episodes_df, locations_df, script_lines_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "975e47a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_episode_documents(episodes_df: pd.DataFrame) -> List[Dict]:\n",
    "    \"\"\"Create structured documents from episodes data\"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    for _, episode in episodes_df.iterrows():\n",
    "        # Create comprehensive episode description\n",
    "        content = f\"\"\"\n",
    "        Episode: {episode['title']}\n",
    "        Season: {episode['season']}\n",
    "        Episode Number: {episode['number_in_season']}\n",
    "        Series Number: {episode['number_in_series']}\n",
    "        Air Date: {episode['original_air_date']}\n",
    "        IMDB Rating: {episode['imdb_rating']}\n",
    "        US Viewers: {episode['us_viewers_in_millions']} million\n",
    "        Production Code: {episode['production_code']}\n",
    "        \"\"\"\n",
    "        \n",
    "        documents.append({\n",
    "            'content': content.strip(),\n",
    "            'metadata': {\n",
    "                'type': 'episode',\n",
    "                'episode_id': episode['id'],\n",
    "                'title': episode['title'],\n",
    "                'season': episode['season'],\n",
    "                'imdb_rating': episode['imdb_rating'],\n",
    "                'air_date': episode['original_air_date']\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f56f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_character_documents(characters_df: pd.DataFrame) -> List[Dict]:\n",
    "    \"\"\"Create structured documents from characters data\"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    for _, character in characters_df.iterrows():\n",
    "        content = f\"\"\"\n",
    "        Character: {character['name']}\n",
    "        Gender: {character['gender']}\n",
    "        Normalized Name: {character['normalized_name']}\n",
    "        \"\"\"\n",
    "        \n",
    "        documents.append({\n",
    "            'content': content.strip(),\n",
    "            'metadata': {\n",
    "                'type': 'character',\n",
    "                'character_id': character['id'],\n",
    "                'name': character['name'],\n",
    "                'gender': character['gender']\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7148953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_location_documents(locations_df: pd.DataFrame) -> List[Dict]:\n",
    "    \"\"\"Create structured documents from locations data\"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    for _, location in locations_df.iterrows():\n",
    "        content = f\"\"\"\n",
    "        Location: {location['name']}\n",
    "        Normalized Name: {location['normalized_name']}\n",
    "        \"\"\"\n",
    "        \n",
    "        documents.append({\n",
    "            'content': content.strip(),\n",
    "            'metadata': {\n",
    "                'type': 'location',\n",
    "                'location_id': location['id'],\n",
    "                'name': location['name']\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "666eb35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_script_documents(script_lines_df: pd.DataFrame, episodes_df: pd.DataFrame, \n",
    "                          characters_df: pd.DataFrame, locations_df: pd.DataFrame) -> List[Dict]:\n",
    "    \"\"\"Create structured documents from script lines with context\"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    # Create lookup dictionaries for faster access\n",
    "    episode_lookup = episodes_df.set_index('id')['title'].to_dict()\n",
    "    character_lookup = characters_df.set_index('id')['name'].to_dict()\n",
    "    location_lookup = locations_df.set_index('id')['name'].to_dict()\n",
    "    \n",
    "    # Group script lines by episode for context\n",
    "    grouped_scripts = script_lines_df.groupby('episode_id')\n",
    "    \n",
    "    for episode_id, episode_lines in grouped_scripts:\n",
    "        episode_title = episode_lookup.get(episode_id, f\"Episode {episode_id}\")\n",
    "        \n",
    "        # Combine multiple lines for richer context\n",
    "        episode_script = []\n",
    "        for _, line in episode_lines.iterrows():\n",
    "            if pd.notna(line['spoken_words']) and line['spoken_words'].strip():\n",
    "                character_name = character_lookup.get(int(line['character_id']), 'Unknown') if pd.notna(line['character_id']) else 'Unknown'\n",
    "                location_name = location_lookup.get(line['location_id'], 'Unknown') if pd.notna(line['location_id']) else 'Unknown'\n",
    "                \n",
    "                script_text = f\"{character_name}: {line['spoken_words']}\"\n",
    "                if location_name != 'Unknown':\n",
    "                    script_text += f\" [Location: {location_name}]\"\n",
    "                \n",
    "                episode_script.append(script_text)\n",
    "        \n",
    "        # Join all lines for the episode\n",
    "        full_script = \"\\n\".join(episode_script)\n",
    "        \n",
    "        if full_script.strip():\n",
    "            documents.append({\n",
    "                'content': f\"Episode: {episode_title}\\n\\nScript:\\n{full_script}\",\n",
    "                'metadata': {\n",
    "                    'type': 'script',\n",
    "                    'episode_id': episode_id,\n",
    "                    'episode_title': episode_title,\n",
    "                    'line_count': len(episode_script)\n",
    "                }\n",
    "            })\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7b5be4",
   "metadata": {},
   "source": [
    "# Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71405ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_documents(documents: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"Split documents using RecursiveCharacterTextSplitter\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \":\", \".\", \"!\", \"?\", \",\", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    split_docs = []\n",
    "    \n",
    "    for doc in documents:\n",
    "        chunks = text_splitter.split_text(doc['content'])\n",
    "        \n",
    "        for i, chunk in enumerate(chunks):\n",
    "            split_docs.append({\n",
    "                'content': chunk,\n",
    "                'metadata': {\n",
    "                    **doc['metadata'],\n",
    "                    'chunk_id': i,\n",
    "                    'total_chunks': len(chunks)\n",
    "                }\n",
    "            })\n",
    "    \n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7d4c58",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f551c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "\n",
    "def create_embeddings(documents: List[Dict]) -> tuple:\n",
    "    \"\"\"Create embeddings for all documents\"\"\"\n",
    "    texts = [doc['content'] for doc in documents]\n",
    "    # embeddings = embedding_model.encode(texts, convert_to_tensor=False)\n",
    "    embeddings: List[List] = embedding_model.get_text_embedding_batch(texts, show_progress=True)\n",
    "    embeddings: np.ndarray = np.array(embeddings, dtype=np.float32)\n",
    "    return embeddings, texts, [doc['metadata'] for doc in documents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecf69c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faiss import write_index, read_index\n",
    "def build_faiss_index(embeddings: np.ndarray, output_path: str) -> faiss.Index:\n",
    "\t\"\"\"Build FAISS index for similarity search\"\"\"\n",
    "\toutput_path = \"output/simpsons.index\"\n",
    "\tif os.path.exists(output_path):\n",
    "\t\tprint(f\"Loading existing index from {output_path}\")\n",
    "\t\tindex = read_index(output_path)\n",
    "\t\treturn index\n",
    "\n",
    "\tdimension = embeddings.shape[1]\n",
    "\tindex = faiss.IndexFlatIP(dimension)  # Inner product for cosine similarity\n",
    "\t# Normalize embeddings for cosine similarity\n",
    "\tfaiss.normalize_L2(embeddings)\n",
    "\tindex.add(embeddings.astype('float32'))\n",
    "\tos.makedirs(\"output\", exist_ok=True)\n",
    "\twrite_index(index, \"output/simpsons.index\")\n",
    "\treturn index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5f03b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_similar_documents(query: str, index: faiss.Index, texts: List[str], \n",
    "                           metadata: List[Dict], k: int = 5) -> List[Dict]:\n",
    "    \"\"\"Search for k similar documents using FAISS index\"\"\"\n",
    "    query_embedding = embedding_model.get_text_embedding_batch([query])\n",
    "    query_embedding: np.ndarray = np.array(query_embedding, dtype=np.float32)\n",
    "    faiss.normalize_L2(query_embedding)\n",
    "    \n",
    "    scores, indices = index.search(query_embedding.astype('float32'), k)\n",
    "    \n",
    "    results = []\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        results.append({\n",
    "            'content': texts[idx],\n",
    "            'metadata': metadata[idx],\n",
    "            'score': float(scores[0][i])\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1053c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "# Initialize Ollama LLM\n",
    "# https://docs.llamaindex.ai/en/stable/api_reference/llms/ollama/\n",
    "llm = Ollama(\n",
    "    model=config[\"OLLAMA_LLM_MODEL\"],\n",
    "    temperature=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06d743d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "def generate_response(llm, query: str, context_docs: List[Dict]) -> str:\n",
    "\t\"\"\"Generate response using OpenAI with retrieved context\"\"\"\n",
    "\t# Prepare context from retrieved documents\n",
    "\tcontext = \"\"\n",
    "\tfor doc in context_docs:\n",
    "\t\tdoc_type = doc['metadata']['type']\n",
    "\t\tcontext += f\"[{doc_type.upper()}] {doc['content']}\\n\\n\"\n",
    "\n",
    "\t# Create prompt\n",
    "\tprompt = f\"\"\"\n",
    "\tYou are a knowledgeable assistant about The Simpsons TV show. Use the following context to answer the user's question.\n",
    "\n",
    "\tContext:\n",
    "\t{context}\n",
    "\n",
    "\tQuestion: {query}\n",
    "\n",
    "\tPlease provide a comprehensive answer based on the context provided. If the context doesn't contain enough information to fully answer the question, mention what information is available and what might be missing.\n",
    "\n",
    "\tAnswer:\n",
    "\t\"\"\"\n",
    "\n",
    "\tmessages = [\n",
    "\t\tChatMessage(\n",
    "\t\t\trole=\"system\", \n",
    "   \t\t\tcontent=\"You are a helpful assistant specializing in The Simpsons TV show.\",\n",
    "\t\t),\n",
    "\t\tChatMessage(\n",
    "\t\t\trole=\"user\",\n",
    "\t\t\tcontent=prompt\n",
    "\t\t)\n",
    "\t]\n",
    "\tresponse = llm.chat(messages)\n",
    "\treturn response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1058dc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Simpsons data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/85/py72kfsd3zlgfwv2_dp2wb5m0000gn/T/ipykernel_88976/515446283.py:7: DtypeWarning: Columns (4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  script_lines_df = pd.read_csv('../data/simpsons/simpsons_script_lines.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6722 characters, 600 episodes, 4459 locations, 158271 script lines\n",
      "Creating documents...\n",
      "Total documents before splitting: 12345\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Simpsons data...\")\n",
    "characters_df, episodes_df, locations_df, script_lines_df = load_simpsons_data()\n",
    "\n",
    "print(\"Creating documents...\")\n",
    "episode_docs = create_episode_documents(episodes_df)\n",
    "character_docs = create_character_documents(characters_df)\n",
    "location_docs = create_location_documents(locations_df)\n",
    "script_docs = create_script_documents(script_lines_df, episodes_df, characters_df, locations_df)\n",
    "\n",
    "# Combine all documents\n",
    "all_documents = episode_docs + character_docs + location_docs + script_docs\n",
    "\n",
    "print(f\"Total documents before splitting: {len(all_documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f7e06ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting documents...\n",
      "Total document chunks: 28544\n",
      "Creating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7104f8993547ddb25db8a7eeba0e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/28544 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal document chunks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(split_docs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCreating embeddings...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m embeddings, texts, metadata = \u001b[43mcreate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_docs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mcreate_embeddings\u001b[39m\u001b[34m(documents)\u001b[39m\n\u001b[32m      5\u001b[39m texts = [doc[\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# embeddings = embedding_model.encode(texts, convert_to_tensor=False)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m embeddings: List[List] = \u001b[43membedding_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_text_embedding_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m embeddings: np.ndarray = np.array(embeddings, dtype=np.float32)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings, texts, [doc[\u001b[33m'\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Loka/Pycon2025/graph-rag-simpsons/.venv/lib/python3.11/site-packages/llama_index_instrumentation/dispatcher.py:319\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    316\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    322\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Loka/Pycon2025/graph-rag-simpsons/.venv/lib/python3.11/site-packages/llama_index/core/base/embeddings/base.py:406\u001b[39m, in \u001b[36mBaseEmbedding.get_text_embedding_batch\u001b[39m\u001b[34m(self, texts, show_progress, **kwargs)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.event(\n\u001b[32m    402\u001b[39m     CBEventType.EMBEDDING,\n\u001b[32m    403\u001b[39m     payload={EventPayload.SERIALIZED: \u001b[38;5;28mself\u001b[39m.to_dict()},\n\u001b[32m    404\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embeddings_cache:\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m         embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_text_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    407\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embeddings_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    408\u001b[39m         embeddings = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Loka/Pycon2025/graph-rag-simpsons/.venv/lib/python3.11/site-packages/llama_index/embeddings/ollama/base.py:77\u001b[39m, in \u001b[36mOllamaEmbedding._get_text_embeddings\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m     75\u001b[39m embeddings_list: List[List[\u001b[38;5;28mfloat\u001b[39m]] = []\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_general_text_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m     embeddings_list.append(embeddings)\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings_list\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Loka/Pycon2025/graph-rag-simpsons/.venv/lib/python3.11/site-packages/llama_index/embeddings/ollama/base.py:90\u001b[39m, in \u001b[36mOllamaEmbedding.get_general_text_embedding\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_general_text_embedding\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: \u001b[38;5;28mstr\u001b[39m) -> List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m     89\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get Ollama embedding.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mollama_additional_kwargs\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[33m\"\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Loka/Pycon2025/graph-rag-simpsons/.venv/lib/python3.11/site-packages/ollama/_client.py:390\u001b[39m, in \u001b[36mClient.embeddings\u001b[39m\u001b[34m(self, model, prompt, options, keep_alive)\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membeddings\u001b[39m(\n\u001b[32m    381\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    382\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    385\u001b[39m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    386\u001b[39m ) -> EmbeddingsResponse:\n\u001b[32m    387\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    388\u001b[39m \u001b[33;03m  Deprecated in favor of `embed`.\u001b[39;00m\n\u001b[32m    389\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mEmbeddingsResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/api/embeddings\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEmbeddingsRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m      \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Loka/Pycon2025/graph-rag-simpsons/.venv/lib/python3.11/site-packages/ollama/_client.py:180\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, cls, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    176\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**part)\n\u001b[32m    178\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Loka/Pycon2025/graph-rag-simpsons/.venv/lib/python3.11/site-packages/ollama/_client.py:120\u001b[39m, in \u001b[36mClient._request_raw\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_request_raw\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    119\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     r = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m     r.raise_for_status()\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Loka/Pycon2025/graph-rag-simpsons/.venv/lib/python3.11/site-packages/httpx/_client.py:825\u001b[39m, in \u001b[36mClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m    810\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m    812\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m    813\u001b[39m     method=method,\n\u001b[32m    814\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    823\u001b[39m     extensions=extensions,\n\u001b[32m    824\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Loka/Pycon2025/graph-rag-simpsons/.venv/lib/python3.11/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Loka/Pycon2025/graph-rag-simpsons/.venv/lib/python3.11/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Loka/Pycon2025/graph-rag-simpsons/.venv/lib/python3.11/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Loka/Pycon2025/graph-rag-simpsons/.venv/lib/python3.11/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Loka/Pycon2025/graph-rag-simpsons/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Loka/Pycon2025/graph-rag-simpsons/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Loka/Pycon2025/graph-rag-simpsons/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Loka/Pycon2025/graph-rag-simpsons/.venv/lib/python3.11/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Loka/Pycon2025/graph-rag-simpsons/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Loka/Pycon2025/graph-rag-simpsons/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Loka/Pycon2025/graph-rag-simpsons/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Loka/Pycon2025/graph-rag-simpsons/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Loka/Pycon2025/graph-rag-simpsons/.venv/lib/python3.11/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"Splitting documents...\")\n",
    "split_docs = split_documents(all_documents)\n",
    "\n",
    "print(f\"Total document chunks: {len(split_docs)}\")\n",
    "\n",
    "print(\"Creating embeddings...\")\n",
    "embeddings, texts, metadata = create_embeddings(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ebc079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_simpsons_rag():\n",
    "    \"\"\"Main function to set up the RAG system\"\"\"\n",
    "    print(\"Setting up OpenAI client...\")\n",
    "    \n",
    "    print(\"Loading Simpsons data...\")\n",
    "    characters_df, episodes_df, locations_df, script_lines_df = load_simpsons_data()\n",
    "    \n",
    "    print(\"Creating documents...\")\n",
    "    episode_docs = create_episode_documents(episodes_df)\n",
    "    character_docs = create_character_documents(characters_df)\n",
    "    location_docs = create_location_documents(locations_df)\n",
    "    script_docs = create_script_documents(script_lines_df, episodes_df, characters_df, locations_df)\n",
    "    \n",
    "    # Combine all documents\n",
    "    all_documents = episode_docs + character_docs + location_docs + script_docs\n",
    "    \n",
    "    print(f\"Total documents before splitting: {len(all_documents)}\")\n",
    "    \n",
    "    print(\"Splitting documents...\")\n",
    "    split_docs = split_documents(all_documents)\n",
    "    \n",
    "    print(f\"Total document chunks: {len(split_docs)}\")\n",
    "    \n",
    "    print(\"Creating embeddings...\")\n",
    "    embeddings, texts, metadata = create_embeddings(split_docs)\n",
    "    \n",
    "    print(\"Building FAISS index...\")\n",
    "    index = build_faiss_index(embeddings)\n",
    "    \n",
    "    print(\"RAG system setup complete!\")\n",
    "    \n",
    "    return index, texts, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c26b129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_simpsons_rag(llm, query: str, index: faiss.Index, texts: List[str], metadata: List[Dict]) -> str:\n",
    "    \"\"\"Query the Simpsons RAG system\"\"\"\n",
    "    print(f\"Searching for: {query}\")\n",
    "    \n",
    "    # Retrieve relevant documents\n",
    "    relevant_docs = search_similar_documents(query, index, texts, metadata, k=5)\n",
    "    print(f\"Found {len(relevant_docs)} relevant documents\")\n",
    "    \n",
    "    # Generate response\n",
    "    response = generate_response(llm, query, relevant_docs)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "593d6fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "llm = Ollama(\n",
    "    model=config[\"OLLAMA_LLM_MODEL\"], \n",
    "    request_timeout=7200.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8fe789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Query: Which episode has the most lines by Lisa?\n",
      "==================================================\n",
      "(1, 1024)\n",
      "\n",
      "==================================================\n",
      "Query: In what season did Milhouse appear most?\n",
      "==================================================\n",
      "(1, 1024)\n",
      "\n",
      "==================================================\n",
      "Query: Which characters were in the same location most often as Mr. Burns?\n",
      "==================================================\n",
      "(1, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Example queries\n",
    "sample_queries = [\n",
    "    \"Which episode has the most lines by Lisa?\",\n",
    "    \"In what season did Milhouse appear most?\",\n",
    "    \"Which characters were in the same location most often as Mr. Burns?\",\n",
    "]\n",
    "\n",
    "for query in sample_queries:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # response = query_simpsons_rag(llm, query, index, texts, metadata)\n",
    "    search_similar_documents(query, index, texts, metadata, 10)\n",
    "    # print(f\"Response: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
